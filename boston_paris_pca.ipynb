{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "cdcf338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,r2_score,mean_absolute_percentage_error\n",
    ")\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rnd\n",
    "from sklearn.decomposition import PCA\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import neptune\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop, Adagrad\n",
    "import optuna\n",
    "import neptune\n",
    "from neptune_optuna import NeptuneCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "d886f91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston=pd.read_csv('C:\\\\Users\\\\kiril\\\\Downloads\\\\Telegram Desktop\\\\BostonHousing 2.csv')\n",
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "c2872e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       501 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  b        506 non-null    float64\n",
      " 12  lstat    506 non-null    float64\n",
      " 13  medv     506 non-null    float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_boston.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e182559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boston=df_boston.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b98df637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        b  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "23911d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_boston=df_boston.drop(['medv'],axis=1)\n",
    "y_boston=df_boston['medv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5bbf3675",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_boston, X_test_boston, y_train_boston, y_test_boston = train_test_split(\n",
    "    X_boston, y_boston, random_state=42, test_size=0.2\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "33ea58d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_boston=StandardScaler()\n",
    "X_train_scaled_boston=scaler_boston.fit_transform(X_train_boston)\n",
    "X_test_scaled_boston=scaler_boston.transform(X_test_boston)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "bf98ef6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.86865849,  0.45892677, -0.03778806, ..., -0.25488474,\n",
       "         0.17929979, -0.0913963 ],\n",
       "       [ 0.52401652, -0.25317188, -2.04191776, ..., -0.04469517,\n",
       "         0.05447555,  0.07222612],\n",
       "       [-1.21755915,  0.30292582, -1.19323138, ..., -0.09684296,\n",
       "         0.3872695 , -0.03115836],\n",
       "       ...,\n",
       "       [-4.79334455,  2.24164151,  0.49843414, ...,  1.34512331,\n",
       "         0.83800322, -0.68784014],\n",
       "       [ 3.87859039,  0.93146365, -0.00870598, ..., -0.12436791,\n",
       "         0.55379986, -0.00835374],\n",
       "       [ 0.59259092, -0.40129322, -1.58966512, ..., -0.51816465,\n",
       "        -0.38024072,  0.34930445]], shape=(400, 13))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_boston=PCA()\n",
    "pca_boston.fit_transform(X_train_scaled_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "80e2d94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1, X_boston.shape[1]+1,1), np.cumsum(pca_boston.explained_variance_ratio_\n",
    "), marker='o')\n",
    "plt.axhline(y=0.95,color='red')\n",
    "plt.title(\"PCA with normalization\")\n",
    "plt.xlabel(\"  (n_components)\")\n",
    "plt.ylabel(\"   \")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "81b377b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_boston=PCA(n_components=9)\n",
    "X_train_pca_boston=pca_boston.fit_transform(X_train_scaled_boston)\n",
    "X_test_pca_boston=pca_boston.transform(X_test_scaled_boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "b4b8187b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kiril\\anaconda3\\envs\\MLops_main\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 32ms/step - loss: 581.8116 - mae: 22.3555 - val_loss: 508.9803 - val_mae: 21.1082\n",
      "Epoch 2/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 524.6132 - mae: 21.1430 - val_loss: 435.4684 - val_mae: 19.3763\n",
      "Epoch 3/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 437.8014 - mae: 19.0685 - val_loss: 327.8307 - val_mae: 16.5446\n",
      "Epoch 4/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 313.5330 - mae: 15.7406 - val_loss: 187.9388 - val_mae: 12.0874\n",
      "Epoch 5/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 166.6043 - mae: 10.9281 - val_loss: 69.2238 - val_mae: 6.8032\n",
      "Epoch 6/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 63.4877 - mae: 6.1706 - val_loss: 34.4158 - val_mae: 5.0686\n",
      "Epoch 7/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 32.9569 - mae: 4.1783 - val_loss: 34.4780 - val_mae: 4.5955\n",
      "Epoch 8/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 26.5250 - mae: 3.7231 - val_loss: 31.5303 - val_mae: 3.9972\n",
      "Epoch 9/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 24.1604 - mae: 3.5103 - val_loss: 29.2183 - val_mae: 3.7489\n",
      "Epoch 10/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 23.0478 - mae: 3.4013 - val_loss: 30.1285 - val_mae: 3.7701\n",
      "Epoch 11/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 22.0953 - mae: 3.2977 - val_loss: 28.7025 - val_mae: 3.6366\n",
      "Epoch 12/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 21.4394 - mae: 3.2372 - val_loss: 28.4963 - val_mae: 3.5785\n",
      "Epoch 13/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.8145 - mae: 3.1929 - val_loss: 28.7871 - val_mae: 3.6042\n",
      "Epoch 14/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 20.3973 - mae: 3.1304 - val_loss: 28.0669 - val_mae: 3.5520\n",
      "Epoch 15/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 19.7350 - mae: 3.0920 - val_loss: 29.3076 - val_mae: 3.5854\n",
      "Epoch 16/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 19.3560 - mae: 3.0870 - val_loss: 30.7634 - val_mae: 3.5955\n",
      "Epoch 17/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.9906 - mae: 3.0162 - val_loss: 28.7642 - val_mae: 3.4879\n",
      "Epoch 18/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 18.3984 - mae: 2.9864 - val_loss: 30.3352 - val_mae: 3.5481\n",
      "Epoch 19/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 18.0592 - mae: 2.9555 - val_loss: 30.4704 - val_mae: 3.5327\n",
      "Epoch 20/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 17.6891 - mae: 2.9211 - val_loss: 29.5737 - val_mae: 3.4425\n",
      "Epoch 21/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.5617 - mae: 2.9068 - val_loss: 29.6027 - val_mae: 3.3818\n",
      "Epoch 22/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 17.2683 - mae: 2.8330 - val_loss: 28.1522 - val_mae: 3.3146\n",
      "Epoch 23/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.9087 - mae: 2.8656 - val_loss: 31.4102 - val_mae: 3.4486\n",
      "Epoch 24/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 16.5141 - mae: 2.8366 - val_loss: 31.9337 - val_mae: 3.4698\n",
      "Epoch 25/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.1799 - mae: 2.7906 - val_loss: 31.2416 - val_mae: 3.4002\n",
      "Epoch 26/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 16.1321 - mae: 2.7672 - val_loss: 30.8445 - val_mae: 3.3215\n",
      "Epoch 27/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.7512 - mae: 2.7355 - val_loss: 31.7453 - val_mae: 3.4242\n",
      "Epoch 28/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.5052 - mae: 2.7173 - val_loss: 31.8804 - val_mae: 3.3497\n",
      "Epoch 29/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.3441 - mae: 2.6960 - val_loss: 32.6115 - val_mae: 3.3494\n",
      "Epoch 30/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 15.0578 - mae: 2.6810 - val_loss: 31.3905 - val_mae: 3.2681\n",
      "Epoch 31/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.9797 - mae: 2.6427 - val_loss: 33.1374 - val_mae: 3.3382\n",
      "Epoch 32/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 14.9265 - mae: 2.6218 - val_loss: 31.3434 - val_mae: 3.1854\n",
      "Epoch 33/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 15.1729 - mae: 2.7082 - val_loss: 35.6609 - val_mae: 3.3658\n",
      "Epoch 34/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.4015 - mae: 2.5862 - val_loss: 32.6272 - val_mae: 3.2078\n",
      "Epoch 35/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 14.3540 - mae: 2.5510 - val_loss: 32.5239 - val_mae: 3.2096\n",
      "Epoch 36/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.1699 - mae: 2.5538 - val_loss: 33.0722 - val_mae: 3.1668\n",
      "Epoch 37/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.0731 - mae: 2.5527 - val_loss: 34.7467 - val_mae: 3.2816\n",
      "Epoch 38/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.9424 - mae: 2.5604 - val_loss: 33.7421 - val_mae: 3.1695\n",
      "Epoch 39/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.8781 - mae: 2.5210 - val_loss: 33.3966 - val_mae: 3.1955\n",
      "Epoch 40/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.7981 - mae: 2.5320 - val_loss: 35.0971 - val_mae: 3.2438\n",
      "Epoch 41/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.7883 - mae: 2.5532 - val_loss: 36.3572 - val_mae: 3.3116\n",
      "Epoch 42/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.6777 - mae: 2.5210 - val_loss: 34.0135 - val_mae: 3.1380\n",
      "Epoch 43/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.5371 - mae: 2.4925 - val_loss: 35.1354 - val_mae: 3.1568\n",
      "Epoch 44/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.3602 - mae: 2.4449 - val_loss: 33.3709 - val_mae: 3.1038\n",
      "Epoch 45/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.4676 - mae: 2.4939 - val_loss: 35.8352 - val_mae: 3.1742\n",
      "Epoch 46/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.1213 - mae: 2.4462 - val_loss: 34.6836 - val_mae: 3.0723\n",
      "Epoch 47/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.2116 - mae: 2.4504 - val_loss: 35.4864 - val_mae: 3.1269\n",
      "Epoch 48/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 13.0907 - mae: 2.4344 - val_loss: 35.0816 - val_mae: 3.0689\n",
      "Epoch 49/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.0094 - mae: 2.4300 - val_loss: 33.2972 - val_mae: 2.9855\n",
      "Epoch 50/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.8967 - mae: 2.4194 - val_loss: 36.7831 - val_mae: 3.1773\n",
      "Epoch 51/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.8642 - mae: 2.4393 - val_loss: 35.8162 - val_mae: 3.1043\n",
      "Epoch 52/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 13.0884 - mae: 2.4048 - val_loss: 35.1284 - val_mae: 3.0391\n",
      "Epoch 53/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.9010 - mae: 2.4647 - val_loss: 35.0029 - val_mae: 3.0669\n",
      "Epoch 54/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.7188 - mae: 2.4243 - val_loss: 35.7668 - val_mae: 3.0983\n",
      "Epoch 55/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.6789 - mae: 2.3847 - val_loss: 36.6785 - val_mae: 3.1434\n",
      "Epoch 56/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.6076 - mae: 2.3872 - val_loss: 36.6858 - val_mae: 3.0878\n",
      "Epoch 57/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.5723 - mae: 2.4049 - val_loss: 35.8392 - val_mae: 3.0707\n",
      "Epoch 58/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5910 - mae: 2.3924 - val_loss: 35.4273 - val_mae: 3.0170\n",
      "Epoch 59/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5404 - mae: 2.3856 - val_loss: 34.3459 - val_mae: 3.0149\n",
      "Epoch 60/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.4555 - mae: 2.3572 - val_loss: 34.2913 - val_mae: 2.9135\n",
      "Epoch 61/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.4507 - mae: 2.3623 - val_loss: 36.6982 - val_mae: 3.0524\n",
      "Epoch 62/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2981 - mae: 2.3525 - val_loss: 35.8306 - val_mae: 3.0049\n",
      "Epoch 63/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.4810 - mae: 2.4020 - val_loss: 35.4108 - val_mae: 3.0062\n",
      "Epoch 64/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.5724 - mae: 2.3296 - val_loss: 34.8548 - val_mae: 2.9730\n",
      "Epoch 65/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.7603 - mae: 2.4490 - val_loss: 36.6551 - val_mae: 3.0575\n",
      "Epoch 66/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.2159 - mae: 2.3096 - val_loss: 35.7822 - val_mae: 2.9802\n",
      "Epoch 67/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.2286 - mae: 2.3747 - val_loss: 35.9038 - val_mae: 3.0007\n",
      "Epoch 68/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.2530 - mae: 2.3612 - val_loss: 34.6175 - val_mae: 2.9478\n",
      "Epoch 69/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.1166 - mae: 2.2963 - val_loss: 33.8385 - val_mae: 2.8933\n",
      "Epoch 70/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 12.1730 - mae: 2.3617 - val_loss: 36.7819 - val_mae: 3.0652\n",
      "Epoch 71/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 12.1424 - mae: 2.3033 - val_loss: 35.5274 - val_mae: 2.9979\n",
      "Epoch 72/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.8434 - mae: 2.3130 - val_loss: 34.8880 - val_mae: 2.9196\n",
      "Epoch 73/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.9188 - mae: 2.3394 - val_loss: 34.9151 - val_mae: 2.9414\n",
      "Epoch 74/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 11.8331 - mae: 2.2996 - val_loss: 36.5122 - val_mae: 3.0683\n",
      "Epoch 75/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.8193 - mae: 2.3121 - val_loss: 36.9447 - val_mae: 3.1027\n",
      "Epoch 76/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.7213 - mae: 2.2893 - val_loss: 36.1379 - val_mae: 2.9760\n",
      "Epoch 77/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.6813 - mae: 2.2961 - val_loss: 36.0334 - val_mae: 2.9867\n",
      "Epoch 78/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 11.6356 - mae: 2.2572 - val_loss: 33.8472 - val_mae: 2.8609\n",
      "Epoch 79/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.5836 - mae: 2.2727 - val_loss: 36.1798 - val_mae: 2.9779\n",
      "Epoch 80/80\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 11.5673 - mae: 2.3046 - val_loss: 36.8028 - val_mae: 3.0278\n",
      "min train MSE: 11.567264556884766 ( 80)\n",
      "min train MAE: 2.2572195529937744 ( 78)\n",
      "MSE  : 13.197068214416504\n",
      "MAE  : 2.8101532459259033\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(36, input_shape=(9,), activation='leaky_relu'))\n",
    "model.add(Dense(18,activation='leaky_relu'))\n",
    "model.add(Dense(6,activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "history = model.fit(X_train_pca_boston, y_train_boston, epochs=80, batch_size=16, verbose=1,validation_split=0.1)\n",
    "\n",
    "train_mse = history.history['loss']\n",
    "train_mae = history.history['mae']\n",
    "\n",
    "min_train_mse = min(train_mse)\n",
    "min_train_mse_epoch = train_mse.index(min_train_mse) + 1\n",
    "\n",
    "min_train_mae = min(train_mae)\n",
    "min_train_mae_epoch = train_mae.index(min_train_mae) + 1\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test_pca_boston, y_test_boston, verbose=0)\n",
    "\n",
    "\n",
    "print(f'min train MSE: {min_train_mse} ( {min_train_mse_epoch})')\n",
    "print(f'min train MAE: {min_train_mae} ( {min_train_mae_epoch})')\n",
    "\n",
    "\n",
    "print(f\"MSE  : {test_loss}\")\n",
    "print(f\"MAE  : {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "08a71025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_mse, label='Train MAE', color='blue',marker='o',markersize=5,markeredgecolor='red',markerfacecolor='red')\n",
    "plt.title('MSE  ')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True,alpha=0.3)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_mae, label='Train MAE', color='blue',marker='o',markersize=5,markeredgecolor='red',markerfacecolor='red')\n",
    "plt.title('MAE  ')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True,alpha=0.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "d20a5735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.995230571992426 vs MAE 3.2772638118499753\n"
     ]
    }
   ],
   "source": [
    "reg=LinearRegression().fit(X_boston,y_boston)\n",
    "y_pred_boston = reg.predict(X_boston)\n",
    "mse_linreg_boston = mean_squared_error(y_boston, y_pred_boston)\n",
    "mae_linreg_boston = mean_absolute_error(y_boston, y_pred_boston)\n",
    "\n",
    "print(f\"MSE: {mse_linreg_boston} vs MAE {mae_linreg_boston}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d78df7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-69\n",
      "100%|| 15/15 [01:15<00:00,  5.02s/trial, best loss: 11.768757820129395]\n",
      "n_layers: 3\n",
      "lr: 0.009461316037864346\n",
      "batch_size: 16\n",
      "epochs: 20\n",
      "optimizer: Adam\n",
      "neurons: [36, 30, 18]\n",
      "activations: ['leaky_relu', 'leaky_relu', 'relu']\n",
      "Train MSE: 12.967476844787598 vs Test MSE: 14.926997184753418\n",
      "Train MAE: 2.4576423168182373 vs Test MAE: 2.8688251972198486\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 15 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 15 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-69/metadata\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run( project=\"kulikovka/paris-boston-test\",\n",
    "                        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiNjZjNWE3OS1jMzRlLTQyZjAtYmFiNi04ZGU1ZjY0MDAxNzgifQ==\", )\n",
    "\n",
    "\n",
    "space_sequential = {\n",
    "    'n_layers': hp.quniform('n_layers', 2, 6, 1),\n",
    "    'neurons': [hp.quniform(f'neurons_l{i}', 6, 36, 6) for i in range(6)],\n",
    "    'activations': [hp.choice(f'activation_l{i}', ['relu', 'leaky_relu']) for i in range(6)],\n",
    "    'lr': hp.loguniform('lr', np.log(1e-5), np.log(1e-1)),\n",
    "    'batch_size': hp.choice('batch_size', [4, 8, 16, 32, 64]),\n",
    "    'epochs': hp.quniform('epochs', 15, 35, 5),\n",
    "    'optimizer': hp.choice('optimizer', ['Adam', 'SGD', 'RMSprop', 'Adagrad'])\n",
    "}\n",
    "\n",
    "\n",
    "def build_model_boston(params):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(9,)))\n",
    "    n_layers = int(params['n_layers'])\n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(int(params['neurons'][i]), activation=params['activations'][i]))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    if params['optimizer'] == 'Adam':\n",
    "        opt = Adam(learning_rate=params['lr'])\n",
    "    elif params['optimizer'] == 'SGD':\n",
    "        opt = SGD(learning_rate=params['lr'])\n",
    "    elif params['optimizer'] == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=params['lr'])\n",
    "    else:\n",
    "        opt = Adagrad(learning_rate=params['lr'])\n",
    "\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def objective_sequential_boston(params):\n",
    "    model = build_model_boston(params)\n",
    "    model.fit(\n",
    "        X_train_pca_boston, y_train_boston,\n",
    "        epochs=int(params['epochs']),\n",
    "        batch_size=int(params['batch_size']),\n",
    "        verbose=0,validation_split=0.1\n",
    "    )\n",
    "    _, _ = model.evaluate(X_train_pca_boston, y_train_boston, verbose=0)\n",
    "    test_loss, _ = model.evaluate(X_test_pca_boston, y_test_boston, verbose=0)\n",
    "    return {'loss': test_loss, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "trials = Trials()\n",
    "best_sequential_boston = fmin(\n",
    "    fn=objective_sequential_boston,\n",
    "    space=space_sequential,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=15,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "best_params = {\n",
    "    'n_layers': int(best_sequential_boston['n_layers']),\n",
    "    'lr': best_sequential_boston['lr'],\n",
    "    'batch_size': [4, 8, 16, 32, 64][best_sequential_boston['batch_size']],\n",
    "    'epochs': int(best_sequential_boston['epochs']),\n",
    "    'optimizer': ['Adam', 'SGD', 'RMSprop', 'Adagrad'][best_sequential_boston['optimizer']],\n",
    "    'neurons': [],\n",
    "    'activations': []\n",
    "}\n",
    "\n",
    "for i in range(best_params['n_layers']):\n",
    "    n_key = f'neurons_l{i}'\n",
    "    a_key = f'activation_l{i}'\n",
    "    if n_key in best_sequential_boston:\n",
    "        best_params['neurons'].append(int(best_sequential_boston[n_key]))\n",
    "    if a_key in best_sequential_boston:\n",
    "        best_params['activations'].append(['relu', 'leaky_relu'][best_sequential_boston[a_key]])\n",
    "for key, value in best_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "final_model = build_model_boston(best_params)\n",
    "history = final_model.fit(\n",
    "    X_train_pca_boston, y_train_boston,\n",
    "    epochs=best_params['epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "train_loss, train_mae = final_model.evaluate(X_train_pca_boston, y_train_boston, verbose=0)\n",
    "test_loss, test_mae = final_model.evaluate(X_test_pca_boston, y_test_boston, verbose=0)\n",
    "\n",
    "print(f\"Train MSE: {train_loss} vs Test MSE: {test_loss}\")\n",
    "print(f\"Train MAE: {train_mae} vs Test MAE: {test_mae}\")\n",
    "\n",
    "run[\"best_params/n_layers\"] = best_params['n_layers']\n",
    "run[\"best_params/lr\"] = best_params['lr']\n",
    "run[\"best_params/batch_size\"] = best_params['batch_size']\n",
    "run[\"best_params/epochs\"] = best_params['epochs']\n",
    "run[\"best_params/optimizer\"] = best_params['optimizer']\n",
    "\n",
    "for i in range(best_params['n_layers']):\n",
    "    run[f\"best_params/layer_{i+1}/neurons\"] = best_params['neurons'][i]\n",
    "    run[f\"best_params/layer_{i+1}/activation\"] = best_params['activations'][i]\n",
    "\n",
    "run[\"final_metrics/train_mse\"] = train_loss\n",
    "run[\"final_metrics/test_mse\"] = test_loss\n",
    "run[\"final_metrics/train_mae\"] = train_mae\n",
    "run[\"final_metrics/test_mae\"] = test_mae\n",
    "\n",
    "run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164eb638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "1af936f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:09,328] A new study created in memory with name: no-name-12cc84c6-7bdc-41f3-9534-ff13cb69258d\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:15,371] Trial 0 finished with value: 14.487316642974676 and parameters: {'n_layers': 6, 'lr': 0.00021520458620849357, 'batch_size': 8, 'epochs': 35, 'optimizer': 'SGD', 'neurons_l0': 6, 'activation_l0': 'relu', 'neurons_l1': 30, 'activation_l1': 'relu', 'neurons_l2': 30, 'activation_l2': 'leaky_relu', 'neurons_l3': 24, 'activation_l3': 'leaky_relu', 'neurons_l4': 12, 'activation_l4': 'leaky_relu', 'neurons_l5': 24, 'activation_l5': 'leaky_relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:19,685] Trial 1 finished with value: 17.738617565468044 and parameters: {'n_layers': 4, 'lr': 0.0008010473305383084, 'batch_size': 8, 'epochs': 25, 'optimizer': 'SGD', 'neurons_l0': 24, 'activation_l0': 'relu', 'neurons_l1': 18, 'activation_l1': 'relu', 'neurons_l2': 18, 'activation_l2': 'leaky_relu', 'neurons_l3': 6, 'activation_l3': 'relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:23,267] Trial 2 finished with value: 496.65498011139977 and parameters: {'n_layers': 2, 'lr': 0.00013523367914813715, 'batch_size': 8, 'epochs': 15, 'optimizer': 'RMSprop', 'neurons_l0': 30, 'activation_l0': 'leaky_relu', 'neurons_l1': 30, 'activation_l1': 'relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:26,886] Trial 3 finished with value: inf and parameters: {'n_layers': 6, 'lr': 0.018648065005763634, 'batch_size': 32, 'epochs': 15, 'optimizer': 'SGD', 'neurons_l0': 6, 'activation_l0': 'leaky_relu', 'neurons_l1': 24, 'activation_l1': 'leaky_relu', 'neurons_l2': 18, 'activation_l2': 'leaky_relu', 'neurons_l3': 30, 'activation_l3': 'relu', 'neurons_l4': 12, 'activation_l4': 'leaky_relu', 'neurons_l5': 12, 'activation_l5': 'leaky_relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:31,599] Trial 4 finished with value: 604.2098402835962 and parameters: {'n_layers': 5, 'lr': 5.0282744788455976e-05, 'batch_size': 32, 'epochs': 30, 'optimizer': 'Adagrad', 'neurons_l0': 30, 'activation_l0': 'relu', 'neurons_l1': 6, 'activation_l1': 'relu', 'neurons_l2': 6, 'activation_l2': 'leaky_relu', 'neurons_l3': 30, 'activation_l3': 'leaky_relu', 'neurons_l4': 30, 'activation_l4': 'leaky_relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:37,839] Trial 5 finished with value: 16.763922407860303 and parameters: {'n_layers': 6, 'lr': 0.0021830326184871557, 'batch_size': 8, 'epochs': 25, 'optimizer': 'Adam', 'neurons_l0': 36, 'activation_l0': 'relu', 'neurons_l1': 30, 'activation_l1': 'leaky_relu', 'neurons_l2': 36, 'activation_l2': 'leaky_relu', 'neurons_l3': 18, 'activation_l3': 'relu', 'neurons_l4': 30, 'activation_l4': 'leaky_relu', 'neurons_l5': 12, 'activation_l5': 'relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:41,513] Trial 6 finished with value: 587.4152461742623 and parameters: {'n_layers': 4, 'lr': 3.6775995922557754e-05, 'batch_size': 16, 'epochs': 15, 'optimizer': 'Adam', 'neurons_l0': 6, 'activation_l0': 'leaky_relu', 'neurons_l1': 24, 'activation_l1': 'relu', 'neurons_l2': 18, 'activation_l2': 'relu', 'neurons_l3': 36, 'activation_l3': 'leaky_relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:50,759] Trial 7 finished with value: 20.42523905934806 and parameters: {'n_layers': 2, 'lr': 0.01797520785336174, 'batch_size': 4, 'epochs': 25, 'optimizer': 'Adam', 'neurons_l0': 12, 'activation_l0': 'relu', 'neurons_l1': 30, 'activation_l1': 'leaky_relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:54,390] Trial 8 finished with value: 243.9952847474326 and parameters: {'n_layers': 5, 'lr': 0.001367714335148436, 'batch_size': 8, 'epochs': 15, 'optimizer': 'Adagrad', 'neurons_l0': 12, 'activation_l0': 'leaky_relu', 'neurons_l1': 18, 'activation_l1': 'leaky_relu', 'neurons_l2': 24, 'activation_l2': 'leaky_relu', 'neurons_l3': 24, 'activation_l3': 'leaky_relu', 'neurons_l4': 24, 'activation_l4': 'leaky_relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:33:59,510] Trial 9 finished with value: 19.416130960636846 and parameters: {'n_layers': 4, 'lr': 0.031336373122563856, 'batch_size': 16, 'epochs': 35, 'optimizer': 'RMSprop', 'neurons_l0': 30, 'activation_l0': 'relu', 'neurons_l1': 6, 'activation_l1': 'leaky_relu', 'neurons_l2': 6, 'activation_l2': 'leaky_relu', 'neurons_l3': 6, 'activation_l3': 'relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:34:03,633] Trial 10 finished with value: 21.83432470483189 and parameters: {'n_layers': 3, 'lr': 0.000225603999473913, 'batch_size': 64, 'epochs': 35, 'optimizer': 'SGD', 'neurons_l0': 12, 'activation_l0': 'relu', 'neurons_l1': 36, 'activation_l1': 'relu', 'neurons_l2': 36, 'activation_l2': 'relu'}. Best is trial 0 with value: 14.487316642974676.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:34:10,633] Trial 11 finished with value: 9.979757733766894 and parameters: {'n_layers': 6, 'lr': 0.0028454303910813057, 'batch_size': 8, 'epochs': 30, 'optimizer': 'Adam', 'neurons_l0': 36, 'activation_l0': 'relu', 'neurons_l1': 36, 'activation_l1': 'leaky_relu', 'neurons_l2': 36, 'activation_l2': 'leaky_relu', 'neurons_l3': 18, 'activation_l3': 'leaky_relu', 'neurons_l4': 6, 'activation_l4': 'relu', 'neurons_l5': 24, 'activation_l5': 'relu'}. Best is trial 11 with value: 9.979757733766894.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:34:17,861] Trial 12 finished with value: 10.95008989653747 and parameters: {'n_layers': 6, 'lr': 0.005045560740349633, 'batch_size': 8, 'epochs': 30, 'optimizer': 'Adam', 'neurons_l0': 18, 'activation_l0': 'relu', 'neurons_l1': 36, 'activation_l1': 'relu', 'neurons_l2': 30, 'activation_l2': 'leaky_relu', 'neurons_l3': 18, 'activation_l3': 'leaky_relu', 'neurons_l4': 6, 'activation_l4': 'relu', 'neurons_l5': 30, 'activation_l5': 'relu'}. Best is trial 11 with value: 9.979757733766894.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:34:23,058] Trial 13 finished with value: 17.207109092419234 and parameters: {'n_layers': 5, 'lr': 0.0053158976123287415, 'batch_size': 64, 'epochs': 30, 'optimizer': 'Adam', 'neurons_l0': 18, 'activation_l0': 'relu', 'neurons_l1': 36, 'activation_l1': 'leaky_relu', 'neurons_l2': 30, 'activation_l2': 'relu', 'neurons_l3': 12, 'activation_l3': 'leaky_relu', 'neurons_l4': 6, 'activation_l4': 'relu'}. Best is trial 11 with value: 9.979757733766894.\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:8: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\2583986923.py:10: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 15, 35, 5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m13/13\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 16:34:31,026] Trial 14 finished with value: 145.59825218578592 and parameters: {'n_layers': 6, 'lr': 0.07437819857090489, 'batch_size': 4, 'epochs': 30, 'optimizer': 'Adam', 'neurons_l0': 24, 'activation_l0': 'relu', 'neurons_l1': 36, 'activation_l1': 'relu', 'neurons_l2': 30, 'activation_l2': 'leaky_relu', 'neurons_l3': 18, 'activation_l3': 'leaky_relu', 'neurons_l4': 6, 'activation_l4': 'relu', 'neurons_l5': 36, 'activation_l5': 'relu'}. Best is trial 11 with value: 9.979757733766894.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 9.979757733766894 vs Test MSE: 14.103562662024766\n",
      "Train MAE: 2.049493160009384 vs Test MAE: 2.8293239876775456\n",
      "n_layers : 6\n",
      "lr : 0.0028454303910813057\n",
      "batch_size : 8\n",
      "epochs : 30\n",
      "optimizer : Adam\n",
      "neurons_l0 : 36\n",
      "activation_l0 : relu\n",
      "neurons_l1 : 36\n",
      "activation_l1 : leaky_relu\n",
      "neurons_l2 : 36\n",
      "activation_l2 : leaky_relu\n",
      "neurons_l3 : 18\n",
      "activation_l3 : leaky_relu\n",
      "neurons_l4 : 6\n",
      "activation_l4 : relu\n",
      "neurons_l5 : 24\n",
      "activation_l5 : relu\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] All 0 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-70/metadata\n"
     ]
    }
   ],
   "source": [
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"kulikovka/paris-boston-test\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiNjZjNWE3OS1jMzRlLTQyZjAtYmFiNi04ZGU1ZjY0MDAxNzgifQ==\"\n",
    ")\n",
    "\n",
    "def objective_optuna_boston(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [4, 8, 16, 32, 64])\n",
    "    epochs = trial.suggest_int('epochs', 15, 35, 5)\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop', 'Adagrad'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(9,)))\n",
    "    for i in range(n_layers):\n",
    "        neurons = trial.suggest_int(f\"neurons_l{i}\", 6, 36, step=6)\n",
    "        activation = trial.suggest_categorical(f\"activation_l{i}\", [\"relu\", \"leaky_relu\"])\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    if optimizer == \"Adam\":\n",
    "        opt = Adam(learning_rate=lr)\n",
    "    elif optimizer == \"SGD\":\n",
    "        opt = SGD(learning_rate=lr)\n",
    "    elif optimizer == \"RMSprop\":\n",
    "        opt = RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        opt = Adagrad(learning_rate=lr)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_pca_boston, y_train_boston,\n",
    "        epochs=epochs, batch_size=batch_size,\n",
    "        verbose=0, validation_split=0.1\n",
    "    )\n",
    "\n",
    "    for i in range(len(history.history['loss'])):\n",
    "        run[\"epoch/train_mse\"].log(history.history['loss'][i])\n",
    "        run[\"epoch/train_mae\"].log(history.history['mae'][i])\n",
    "        run[\"epoch/val_mse\"].log(history.history['val_loss'][i])\n",
    "        run[\"epoch/val_mae\"].log(history.history['val_mae'][i])\n",
    "\n",
    "    y_train_pred = model.predict(X_train_pca_boston)\n",
    "    y_test_pred = model.predict(X_test_pca_boston)\n",
    "\n",
    "    if np.any(np.isnan(y_train_pred)) or np.any(np.isnan(y_test_pred)):\n",
    "        return np.inf\n",
    "\n",
    "    train_mse = mean_squared_error(y_train_boston, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test_boston, y_test_pred)\n",
    "    train_mae = mean_absolute_error(y_train_boston, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test_boston, y_test_pred)\n",
    "\n",
    "    trial.set_user_attr(\"train_mse\", train_mse)\n",
    "    trial.set_user_attr(\"train_mae\", train_mae)\n",
    "    trial.set_user_attr(\"test_mse\", test_mse)\n",
    "    trial.set_user_attr(\"test_mae\", test_mae)\n",
    "\n",
    "    return train_mse\n",
    "\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective_optuna_boston, n_trials=15)\n",
    "\n",
    "best = study.best_trial\n",
    "\n",
    "run[\"best_params/n_layers\"] = best.params['n_layers']\n",
    "run[\"best_params/lr\"] = best.params['lr']\n",
    "run[\"best_params/batch_size\"] = best.params['batch_size']\n",
    "run[\"best_params/epochs\"] = best.params['epochs']\n",
    "run[\"best_params/optimizer\"] = best.params['optimizer']\n",
    "\n",
    "for i in range(best.params['n_layers']):\n",
    "    run[f\"best_params/layer_{i+1}/neurons\"] = best.params[f'neurons_l{i}']\n",
    "    run[f\"best_params/layer_{i+1}/activation\"] = best.params[f'activation_l{i}']\n",
    "\n",
    "run[\"final_metrics/train_mse\"] = best.user_attrs['train_mse']\n",
    "run[\"final_metrics/test_mse\"] = best.user_attrs['test_mse']\n",
    "run[\"final_metrics/train_mae\"] = best.user_attrs['train_mae']\n",
    "run[\"final_metrics/test_mae\"] = best.user_attrs['test_mae']\n",
    "\n",
    "print(f\"Train MSE: {best.user_attrs['train_mse']} vs Test MSE: {best.user_attrs['test_mse']}\")\n",
    "print(f\"Train MAE: {best.user_attrs['train_mae']} vs Test MAE: {best.user_attrs['test_mae']}\")\n",
    "\n",
    "for param, value in best.params.items():\n",
    "    print(f\"{param} : {value}\")\n",
    "\n",
    "run.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "d53087e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>squareMeters</th>\n",
       "      <th>numberOfRooms</th>\n",
       "      <th>hasYard</th>\n",
       "      <th>hasPool</th>\n",
       "      <th>floors</th>\n",
       "      <th>cityCode</th>\n",
       "      <th>cityPartRange</th>\n",
       "      <th>numPrevOwners</th>\n",
       "      <th>made</th>\n",
       "      <th>isNewBuilt</th>\n",
       "      <th>hasStormProtector</th>\n",
       "      <th>basement</th>\n",
       "      <th>attic</th>\n",
       "      <th>garage</th>\n",
       "      <th>hasStorageRoom</th>\n",
       "      <th>hasGuestRoom</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75523</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>9373</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4313</td>\n",
       "      <td>9005</td>\n",
       "      <td>956</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7559081.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80771</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "      <td>39381</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3653</td>\n",
       "      <td>2436</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8085989.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55712</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>34457</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2937</td>\n",
       "      <td>8852</td>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5574642.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32316</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>27939</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>659</td>\n",
       "      <td>7141</td>\n",
       "      <td>359</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3232561.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70429</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "      <td>38045</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8435</td>\n",
       "      <td>2429</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7055052.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   squareMeters  numberOfRooms  hasYard  hasPool  floors  cityCode  \\\n",
       "0         75523              3        0        1      63      9373   \n",
       "1         80771             39        1        1      98     39381   \n",
       "2         55712             58        0        1      19     34457   \n",
       "3         32316             47        0        0       6     27939   \n",
       "4         70429             19        1        1      90     38045   \n",
       "\n",
       "   cityPartRange  numPrevOwners  made  isNewBuilt  hasStormProtector  \\\n",
       "0              3              8  2005           0                  1   \n",
       "1              8              6  2015           1                  0   \n",
       "2              6              8  2021           0                  0   \n",
       "3             10              4  2012           0                  1   \n",
       "4              3              7  1990           1                  0   \n",
       "\n",
       "   basement  attic  garage  hasStorageRoom  hasGuestRoom      price  \n",
       "0      4313   9005     956               0             7  7559081.5  \n",
       "1      3653   2436     128               1             2  8085989.5  \n",
       "2      2937   8852     135               1             9  5574642.1  \n",
       "3       659   7141     359               0             3  3232561.2  \n",
       "4      8435   2429     292               1             4  7055052.0  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_paris=pd.read_csv(\"C:\\\\Users\\\\kiril\\\\Downloads\\\\Telegram Desktop\\\\ParisHousing.csv\")\n",
    "df_paris.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "345a25bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paris=df_paris.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c063f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_paris=df_paris.drop(['price'],axis=1)\n",
    "y_paris = (df_paris['price'])\n",
    "scaler_paris=StandardScaler()\n",
    "X_paris_norm=scaler_paris.fit_transform(X_paris)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_paris_scaled = y_scaler.fit_transform(y_paris.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "886a881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_paris,X_test_paris,y_train_paris,y_test_paris=train_test_split(X_paris_norm,y_paris_scaled,random_state=42,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "4116bd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.91946124e-02, -2.58630405e-02, -4.81790506e-01, ...,\n",
       "         4.44985440e-01,  2.62122332e+00,  1.16386196e+00],\n",
       "       [-8.17048259e-01, -1.57607155e-01, -8.41043754e-01, ...,\n",
       "         6.90209090e-02, -7.33411509e-02, -1.11930931e+00],\n",
       "       [-5.89539615e-01, -2.80159226e-01, -7.36213846e-01, ...,\n",
       "         5.69147782e-01, -5.18088500e-01, -6.69471717e-01],\n",
       "       ...,\n",
       "       [ 8.03331502e-01, -3.26800389e-01, -5.86650752e-01, ...,\n",
       "         1.63630953e+00,  5.14128405e-01,  5.41987102e-01],\n",
       "       [ 8.00578298e-01, -1.00806985e+00,  1.01271156e+00, ...,\n",
       "         2.07458152e+00,  1.16716740e-03, -7.18477595e-01],\n",
       "       [-1.38582074e+00, -1.08639134e+00,  1.65351443e+00, ...,\n",
       "        -1.61467658e+00, -4.39011325e-01, -1.32879204e+00]],\n",
       "      shape=(8000, 16))"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_paris=PCA()\n",
    "pca_paris.fit_transform(X_train_paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "b8ce2091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(np.arange(1, X_paris.shape[1]+1,1), np.cumsum(pca_paris.explained_variance_ratio_\n",
    "), marker='o')\n",
    "plt.axhline(y=0.95,color='red')\n",
    "plt.title(\"PCA with normalization\")\n",
    "plt.xlabel(\"  (n_components)\")\n",
    "plt.ylabel(\"   \")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "c86eb353",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_paris = PCA(n_components=15)\n",
    "X_train_pca_paris = pca_paris.fit_transform(X_train_paris)\n",
    "X_test_pca_paris = pca_paris.transform(X_test_paris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7e04deb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kiril\\anaconda3\\envs\\MLops_main\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:92: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2085 - mae: 0.3130 - val_loss: 0.0327 - val_mae: 0.1462\n",
      "Epoch 2/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0258 - mae: 0.1285 - val_loss: 0.0212 - val_mae: 0.1155\n",
      "Epoch 3/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0190 - mae: 0.1111 - val_loss: 0.0169 - val_mae: 0.1022\n",
      "Epoch 4/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0164 - mae: 0.1035 - val_loss: 0.0154 - val_mae: 0.0985\n",
      "Epoch 5/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0149 - mae: 0.0985 - val_loss: 0.0143 - val_mae: 0.0940\n",
      "Epoch 6/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0141 - mae: 0.0958 - val_loss: 0.0131 - val_mae: 0.0900\n",
      "Epoch 7/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0133 - mae: 0.0927 - val_loss: 0.0131 - val_mae: 0.0905\n",
      "Epoch 8/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0127 - mae: 0.0899 - val_loss: 0.0130 - val_mae: 0.0895\n",
      "Epoch 9/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0848 - val_loss: 0.0113 - val_mae: 0.0814\n",
      "Epoch 10/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0102 - mae: 0.0772 - val_loss: 0.0093 - val_mae: 0.0722\n",
      "Epoch 11/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0086 - mae: 0.0684 - val_loss: 0.0076 - val_mae: 0.0630\n",
      "Epoch 12/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0610 - val_loss: 0.0067 - val_mae: 0.0584\n",
      "Epoch 13/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0559 - val_loss: 0.0057 - val_mae: 0.0528\n",
      "Epoch 14/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0056 - mae: 0.0519 - val_loss: 0.0044 - val_mae: 0.0473\n",
      "Epoch 15/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0043 - mae: 0.0457 - val_loss: 0.0034 - val_mae: 0.0413\n",
      "Epoch 16/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0390 - val_loss: 0.0021 - val_mae: 0.0333\n",
      "Epoch 17/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0320 - val_loss: 0.0013 - val_mae: 0.0264\n",
      "Epoch 18/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 19/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.7343e-04 - mae: 0.0223 - val_loss: 5.0815e-04 - val_mae: 0.0165\n",
      "Epoch 20/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.9160e-04 - mae: 0.0186 - val_loss: 4.6019e-04 - val_mae: 0.0161\n",
      "Epoch 21/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.5013e-04 - mae: 0.0165 - val_loss: 3.2938e-04 - val_mae: 0.0139\n",
      "Epoch 22/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.1432e-04 - mae: 0.0158 - val_loss: 3.8117e-04 - val_mae: 0.0152\n",
      "Epoch 23/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.8601e-04 - mae: 0.0132 - val_loss: 1.9768e-04 - val_mae: 0.0105\n",
      "Epoch 24/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 3.8890e-04 - mae: 0.0149 - val_loss: 2.6883e-04 - val_mae: 0.0129\n",
      "Epoch 25/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0390e-04 - mae: 0.0112 - val_loss: 1.9350e-04 - val_mae: 0.0109\n",
      "Epoch 26/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.5666e-04 - mae: 0.0125 - val_loss: 3.5426e-04 - val_mae: 0.0151\n",
      "Epoch 27/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.6465e-04 - mae: 0.0126 - val_loss: 2.9177e-04 - val_mae: 0.0136\n",
      "Epoch 28/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2280e-04 - mae: 0.0114 - val_loss: 2.7856e-04 - val_mae: 0.0135\n",
      "Epoch 29/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4001e-04 - mae: 0.0116 - val_loss: 1.5880e-04 - val_mae: 0.0101\n",
      "Epoch 30/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.9711e-04 - mae: 0.0107 - val_loss: 2.4610e-04 - val_mae: 0.0123\n",
      "Epoch 31/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.8063e-04 - mae: 0.0128 - val_loss: 3.4050e-04 - val_mae: 0.0148\n",
      "Epoch 32/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.7923e-04 - mae: 0.0102 - val_loss: 1.2344e-04 - val_mae: 0.0088\n",
      "Epoch 33/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1668e-04 - mae: 0.0111 - val_loss: 1.8171e-04 - val_mae: 0.0111\n",
      "Epoch 34/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3733e-04 - mae: 0.0119 - val_loss: 2.0360e-04 - val_mae: 0.0111\n",
      "Epoch 35/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2162e-04 - mae: 0.0086 - val_loss: 1.8194e-04 - val_mae: 0.0103\n",
      "Epoch 36/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.8252e-04 - mae: 0.0101 - val_loss: 1.0508e-04 - val_mae: 0.0085\n",
      "Epoch 37/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.7791e-04 - mae: 0.0101 - val_loss: 2.8003e-04 - val_mae: 0.0132\n",
      "Epoch 38/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3763e-04 - mae: 0.0091 - val_loss: 9.8456e-05 - val_mae: 0.0079\n",
      "Epoch 39/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.4776e-04 - mae: 0.0095 - val_loss: 2.2401e-04 - val_mae: 0.0118\n",
      "Epoch 40/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4937e-04 - mae: 0.0090 - val_loss: 4.5479e-05 - val_mae: 0.0052\n",
      "Epoch 41/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.0137e-04 - mae: 0.0107 - val_loss: 1.0169e-04 - val_mae: 0.0080\n",
      "Epoch 42/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.2806e-04 - mae: 0.0087 - val_loss: 1.0810e-04 - val_mae: 0.0085\n",
      "Epoch 43/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.4474e-04 - mae: 0.0093 - val_loss: 1.2679e-04 - val_mae: 0.0090\n",
      "Epoch 44/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.1598e-04 - mae: 0.0084 - val_loss: 2.7706e-04 - val_mae: 0.0138\n",
      "Epoch 45/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1252e-04 - mae: 0.0103 - val_loss: 1.6345e-04 - val_mae: 0.0104\n",
      "Epoch 46/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.9302e-04 - mae: 0.0104 - val_loss: 1.5727e-04 - val_mae: 0.0101\n",
      "Epoch 47/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.7779e-05 - mae: 0.0066 - val_loss: 1.0910e-04 - val_mae: 0.0084\n",
      "Epoch 48/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3008e-04 - mae: 0.0087 - val_loss: 7.0843e-04 - val_mae: 0.0216\n",
      "Epoch 49/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4666e-04 - mae: 0.0086 - val_loss: 6.3388e-05 - val_mae: 0.0062\n",
      "Epoch 50/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 2.2917e-04 - mae: 0.0105 - val_loss: 2.0358e-04 - val_mae: 0.0111\n",
      "Epoch 51/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.7741e-05 - mae: 0.0067 - val_loss: 5.8917e-05 - val_mae: 0.0060\n",
      "Epoch 52/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.4812e-05 - mae: 0.0074 - val_loss: 2.6070e-05 - val_mae: 0.0039\n",
      "Epoch 53/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4339e-04 - mae: 0.0092 - val_loss: 1.7357e-04 - val_mae: 0.0105\n",
      "Epoch 54/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.1628e-05 - mae: 0.0072 - val_loss: 4.0395e-05 - val_mae: 0.0050\n",
      "Epoch 55/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.4921e-04 - mae: 0.0090 - val_loss: 4.8808e-05 - val_mae: 0.0054\n",
      "Epoch 56/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.9257e-05 - mae: 0.0071 - val_loss: 7.5860e-05 - val_mae: 0.0071\n",
      "Epoch 57/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3902e-04 - mae: 0.0087 - val_loss: 1.1972e-04 - val_mae: 0.0088\n",
      "Epoch 58/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.2531e-05 - mae: 0.0074 - val_loss: 3.9874e-05 - val_mae: 0.0049\n",
      "Epoch 59/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6046e-04 - mae: 0.0092 - val_loss: 1.2409e-04 - val_mae: 0.0090\n",
      "Epoch 60/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.3346e-05 - mae: 0.0067 - val_loss: 2.6352e-05 - val_mae: 0.0038\n",
      "Epoch 61/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.4457e-04 - mae: 0.0084 - val_loss: 1.7981e-04 - val_mae: 0.0106\n",
      "Epoch 62/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.6018e-05 - mae: 0.0062 - val_loss: 8.9207e-05 - val_mae: 0.0075\n",
      "Epoch 63/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4997e-04 - mae: 0.0092 - val_loss: 1.6404e-04 - val_mae: 0.0102\n",
      "Epoch 64/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 9.0561e-05 - mae: 0.0072 - val_loss: 1.4163e-04 - val_mae: 0.0098\n",
      "Epoch 65/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1575e-04 - mae: 0.0082 - val_loss: 1.0688e-04 - val_mae: 0.0081\n",
      "Epoch 66/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1364e-04 - mae: 0.0082 - val_loss: 1.0485e-04 - val_mae: 0.0080\n",
      "Epoch 67/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.5987e-05 - mae: 0.0063 - val_loss: 6.5132e-05 - val_mae: 0.0064\n",
      "Epoch 68/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4518e-04 - mae: 0.0085 - val_loss: 4.4597e-05 - val_mae: 0.0052\n",
      "Epoch 69/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 8.5266e-05 - mae: 0.0065 - val_loss: 5.2097e-05 - val_mae: 0.0058\n",
      "Epoch 70/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 1.3538e-04 - mae: 0.0090 - val_loss: 1.0947e-04 - val_mae: 0.0084\n",
      "Epoch 71/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.7402e-05 - mae: 0.0067 - val_loss: 7.1509e-05 - val_mae: 0.0067\n",
      "Epoch 72/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0940e-04 - mae: 0.0077 - val_loss: 5.4539e-05 - val_mae: 0.0059\n",
      "Epoch 73/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1279e-04 - mae: 0.0078 - val_loss: 2.3158e-04 - val_mae: 0.0123\n",
      "Epoch 74/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6758e-05 - mae: 0.0062 - val_loss: 8.9820e-05 - val_mae: 0.0078\n",
      "Epoch 75/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4243e-04 - mae: 0.0086 - val_loss: 1.1497e-04 - val_mae: 0.0083\n",
      "Epoch 76/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.7032e-05 - mae: 0.0063 - val_loss: 4.1578e-05 - val_mae: 0.0051\n",
      "Epoch 77/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4830e-04 - mae: 0.0088 - val_loss: 3.0721e-05 - val_mae: 0.0044\n",
      "Epoch 78/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.4620e-04 - mae: 0.0079 - val_loss: 2.1371e-05 - val_mae: 0.0037\n",
      "Epoch 79/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.9010e-05 - mae: 0.0042 - val_loss: 3.1063e-05 - val_mae: 0.0044\n",
      "Epoch 80/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.3855e-04 - mae: 0.0082 - val_loss: 4.4649e-05 - val_mae: 0.0055\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  \n",
      "Train MSE: 2.901017251133453e-05 ( 79)\n",
      "Val MSE: 2.137088267772924e-05 ( 78)\n",
      "Train MAE: 0.004153795074671507 ( 79)\n",
      "Val MAE: 0.0036533402744680643 ( 78)\n",
      "Train MSE: 356428037.6459393\n",
      "Train MAE: 15589.10495057677\n",
      "Test MSE: 370568559.4535923\n",
      "Test MAE: 15947.42897131347\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(32, input_shape=(15,), activation='relu'),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_pca_paris, y_train_paris,\n",
    "    epochs=80, batch_size=10,\n",
    "    validation_split=0.1, verbose=1\n",
    ")\n",
    "\n",
    "train_mse = history.history['loss']\n",
    "val_mse = history.history['val_loss']\n",
    "train_mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "min_train_mse = min(train_mse)\n",
    "min_train_mse_epoch = train_mse.index(min_train_mse) + 1\n",
    "min_val_mse = min(val_mse)\n",
    "min_val_mse_epoch = val_mse.index(min_val_mse) + 1\n",
    "\n",
    "min_train_mae = min(train_mae)\n",
    "min_train_mae_epoch = train_mae.index(min_train_mae) + 1\n",
    "min_val_mae = min(val_mae)\n",
    "min_val_mae_epoch = val_mae.index(min_val_mae) + 1\n",
    "\n",
    "y_train_pred_scaled = model.predict(X_train_pca_paris)\n",
    "y_test_pred_scaled = model.predict(X_test_pca_paris)\n",
    "\n",
    "y_train_pred = y_scaler.inverse_transform(y_train_pred_scaled)\n",
    "y_test_pred = y_scaler.inverse_transform(y_test_pred_scaled)\n",
    "\n",
    "y_train_real = y_scaler.inverse_transform(y_train_paris)\n",
    "y_test_real = y_scaler.inverse_transform(y_test_paris)\n",
    "\n",
    "train_mae_real = mean_absolute_error(y_train_real, y_train_pred)\n",
    "train_mse_real = mean_squared_error(y_train_real, y_train_pred)\n",
    "test_mae_real = mean_absolute_error(y_test_real, y_test_pred)\n",
    "test_mse_real = mean_squared_error(y_test_real, y_test_pred)\n",
    "\n",
    "print(f\"Train MSE: {min_train_mse} ( {min_train_mse_epoch})\")\n",
    "print(f\"Val MSE: {min_val_mse} ( {min_val_mse_epoch})\")\n",
    "print(f\"Train MAE: {min_train_mae} ( {min_train_mae_epoch})\")\n",
    "print(f\"Val MAE: {min_val_mae} ( {min_val_mae_epoch})\")\n",
    "\n",
    "print(f\"Train MSE: {train_mse_real}\")\n",
    "print(f\"Train MAE: {train_mae_real}\")\n",
    "print(f\"Test MSE: {test_mse_real}\")\n",
    "print(f\"Test MAE: {test_mae_real}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "fcef11a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(train_mse, label='Train MSE')\n",
    "plt.plot(val_mse, label='Val MSE')\n",
    "plt.title('MSE  ')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(train_mae, label='Train MAE')\n",
    "plt.plot(val_mae, label='Val MAE')\n",
    "plt.title('MAE  ')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "37518d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-72\n",
      "100%|| 5/5 [08:05<00:00, 97.16s/trial, best loss: 0.00022666991571895778] \n",
      "n_layers: 3\n",
      "lr: 0.010981404752605865\n",
      "batch_size: 10\n",
      "epochs: 90\n",
      "optimizer: Adam\n",
      "neurons: [48, 60, 18]\n",
      "activations: ['relu', 'relu', 'relu']\n",
      "Epoch 1/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.0388 - mae: 0.1408 - val_loss: 0.0189 - val_mae: 0.1103\n",
      "Epoch 2/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0192 - mae: 0.1096 - val_loss: 0.0201 - val_mae: 0.1102\n",
      "Epoch 3/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - mae: 0.0916 - val_loss: 0.0096 - val_mae: 0.0715\n",
      "Epoch 4/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0109 - mae: 0.0776 - val_loss: 0.0198 - val_mae: 0.1085\n",
      "Epoch 5/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0108 - mae: 0.0738 - val_loss: 0.0098 - val_mae: 0.0734\n",
      "Epoch 6/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0615 - val_loss: 0.0042 - val_mae: 0.0487\n",
      "Epoch 7/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0569 - val_loss: 0.0035 - val_mae: 0.0464\n",
      "Epoch 8/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0386 - val_loss: 0.0013 - val_mae: 0.0280\n",
      "Epoch 9/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0051 - mae: 0.0524 - val_loss: 0.0042 - val_mae: 0.0514\n",
      "Epoch 10/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0347 - val_loss: 0.0037 - val_mae: 0.0480\n",
      "Epoch 11/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0036 - mae: 0.0427 - val_loss: 0.0089 - val_mae: 0.0718\n",
      "Epoch 12/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0026 - mae: 0.0374 - val_loss: 0.0059 - val_mae: 0.0600\n",
      "Epoch 13/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0030 - mae: 0.0354 - val_loss: 8.1753e-04 - val_mae: 0.0226\n",
      "Epoch 14/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0308 - val_loss: 3.7507e-04 - val_mae: 0.0153\n",
      "Epoch 15/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0283 - val_loss: 7.2461e-04 - val_mae: 0.0206\n",
      "Epoch 16/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 0.0016 - val_mae: 0.0327\n",
      "Epoch 17/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.1656e-04 - mae: 0.0226 - val_loss: 4.9809e-04 - val_mae: 0.0179\n",
      "Epoch 18/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0330 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 19/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0356 - val_loss: 4.5630e-04 - val_mae: 0.0171\n",
      "Epoch 20/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.5160e-04 - mae: 0.0200 - val_loss: 7.9267e-04 - val_mae: 0.0224\n",
      "Epoch 21/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0349 - val_loss: 0.0011 - val_mae: 0.0261\n",
      "Epoch 22/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.3357e-04 - mae: 0.0194 - val_loss: 0.0011 - val_mae: 0.0265\n",
      "Epoch 23/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.7429e-04 - mae: 0.0203 - val_loss: 2.2885e-04 - val_mae: 0.0119\n",
      "Epoch 24/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0018 - mae: 0.0312 - val_loss: 8.5912e-04 - val_mae: 0.0239\n",
      "Epoch 25/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 9.2546e-04 - mae: 0.0226 - val_loss: 6.6822e-04 - val_mae: 0.0212\n",
      "Epoch 26/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0249 - val_loss: 1.8344e-04 - val_mae: 0.0105\n",
      "Epoch 27/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0025 - mae: 0.0292 - val_loss: 2.6507e-04 - val_mae: 0.0122\n",
      "Epoch 28/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 9.9705e-04 - mae: 0.0188 - val_loss: 0.0034 - val_mae: 0.0464\n",
      "Epoch 29/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.7795e-04 - mae: 0.0182 - val_loss: 3.9572e-04 - val_mae: 0.0155\n",
      "Epoch 30/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0238 - val_loss: 8.9587e-04 - val_mae: 0.0243\n",
      "Epoch 31/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1474e-04 - mae: 0.0188 - val_loss: 3.6481e-04 - val_mae: 0.0159\n",
      "Epoch 32/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0255 - val_loss: 0.0018 - val_mae: 0.0317\n",
      "Epoch 33/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0245 - val_loss: 6.2355e-04 - val_mae: 0.0201\n",
      "Epoch 34/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0258 - val_loss: 2.2403e-04 - val_mae: 0.0116\n",
      "Epoch 35/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0253 - val_loss: 7.1257e-04 - val_mae: 0.0214\n",
      "Epoch 36/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0257 - val_loss: 7.4984e-04 - val_mae: 0.0215\n",
      "Epoch 37/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2319e-04 - mae: 0.0109 - val_loss: 4.7064e-04 - val_mae: 0.0167\n",
      "Epoch 38/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0221 - val_loss: 7.7589e-04 - val_mae: 0.0202\n",
      "Epoch 39/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.8627e-04 - mae: 0.0197 - val_loss: 2.0124e-04 - val_mae: 0.0115\n",
      "Epoch 40/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0219 - val_loss: 8.5218e-05 - val_mae: 0.0072\n",
      "Epoch 41/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0265 - val_loss: 4.9537e-04 - val_mae: 0.0169\n",
      "Epoch 42/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.6296e-04 - mae: 0.0132 - val_loss: 0.0019 - val_mae: 0.0336\n",
      "Epoch 43/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0289 - val_loss: 5.6421e-04 - val_mae: 0.0189\n",
      "Epoch 44/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.6488e-04 - mae: 0.0142 - val_loss: 6.9432e-05 - val_mae: 0.0065\n",
      "Epoch 45/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.3190e-04 - mae: 0.0201 - val_loss: 9.0287e-04 - val_mae: 0.0246\n",
      "Epoch 46/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0215 - val_loss: 0.0094 - val_mae: 0.0709\n",
      "Epoch 47/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0149 - val_loss: 1.7089e-04 - val_mae: 0.0100\n",
      "Epoch 48/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0211 - val_loss: 0.0086 - val_mae: 0.0729\n",
      "Epoch 49/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4595e-04 - mae: 0.0083 - val_loss: 1.8166e-05 - val_mae: 0.0031\n",
      "Epoch 50/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7183e-04 - mae: 0.0089 - val_loss: 0.0041 - val_mae: 0.0511\n",
      "Epoch 51/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.7626e-04 - mae: 0.0197 - val_loss: 1.3596e-05 - val_mae: 0.0028\n",
      "Epoch 52/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.0696e-04 - mae: 0.0147 - val_loss: 1.1385e-04 - val_mae: 0.0083\n",
      "Epoch 53/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.7381e-04 - mae: 0.0152 - val_loss: 7.3924e-04 - val_mae: 0.0198\n",
      "Epoch 54/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0276 - val_loss: 1.0882e-04 - val_mae: 0.0081\n",
      "Epoch 55/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 4.0614e-05 - mae: 0.0045 - val_loss: 3.8118e-05 - val_mae: 0.0045\n",
      "Epoch 56/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0210 - val_loss: 1.9742e-05 - val_mae: 0.0034\n",
      "Epoch 57/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.2211e-04 - mae: 0.0083 - val_loss: 1.7362e-04 - val_mae: 0.0102\n",
      "Epoch 58/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.7514e-04 - mae: 0.0188 - val_loss: 5.7414e-05 - val_mae: 0.0065\n",
      "Epoch 59/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0229 - val_loss: 4.0759e-05 - val_mae: 0.0051\n",
      "Epoch 60/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.1298e-04 - mae: 0.0073 - val_loss: 5.3661e-05 - val_mae: 0.0059\n",
      "Epoch 61/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.1280e-04 - mae: 0.0125 - val_loss: 5.2269e-04 - val_mae: 0.0181\n",
      "Epoch 62/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0185 - val_loss: 1.7999e-04 - val_mae: 0.0094\n",
      "Epoch 63/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.0974e-04 - mae: 0.0127 - val_loss: 2.7692e-04 - val_mae: 0.0130\n",
      "Epoch 64/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0229 - val_loss: 0.0014 - val_mae: 0.0263\n",
      "Epoch 65/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.6004e-04 - mae: 0.0109 - val_loss: 7.7160e-05 - val_mae: 0.0070\n",
      "Epoch 66/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.0524e-04 - mae: 0.0210 - val_loss: 4.6496e-04 - val_mae: 0.0168\n",
      "Epoch 67/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.2414e-05 - mae: 0.0064 - val_loss: 4.0910e-05 - val_mae: 0.0051\n",
      "Epoch 68/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0222 - val_loss: 3.1420e-04 - val_mae: 0.0139\n",
      "Epoch 69/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7829e-04 - mae: 0.0147 - val_loss: 1.1643e-05 - val_mae: 0.0026\n",
      "Epoch 70/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.7559e-04 - mae: 0.0133 - val_loss: 0.0017 - val_mae: 0.0334\n",
      "Epoch 71/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.5991e-04 - mae: 0.0166 - val_loss: 6.1993e-05 - val_mae: 0.0056\n",
      "Epoch 72/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0027 - mae: 0.0258 - val_loss: 0.0133 - val_mae: 0.0897\n",
      "Epoch 73/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.4012e-04 - mae: 0.0151 - val_loss: 0.0027 - val_mae: 0.0411\n",
      "Epoch 74/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.4763e-04 - mae: 0.0077 - val_loss: 8.8454e-06 - val_mae: 0.0023\n",
      "Epoch 75/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 5.4725e-05 - mae: 0.0046 - val_loss: 1.6466e-04 - val_mae: 0.0100\n",
      "Epoch 76/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.2993e-04 - mae: 0.0166 - val_loss: 2.3204e-05 - val_mae: 0.0039\n",
      "Epoch 77/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0190 - val_loss: 8.7868e-05 - val_mae: 0.0071\n",
      "Epoch 78/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 3.0269e-04 - mae: 0.0125 - val_loss: 6.9842e-04 - val_mae: 0.0219\n",
      "Epoch 79/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.0065e-04 - mae: 0.0195 - val_loss: 0.0013 - val_mae: 0.0299\n",
      "Epoch 80/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 8.0798e-04 - mae: 0.0172 - val_loss: 1.1548e-04 - val_mae: 0.0077\n",
      "Epoch 81/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 9.4471e-04 - mae: 0.0180 - val_loss: 1.9683e-04 - val_mae: 0.0108\n",
      "Epoch 82/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.3449e-04 - mae: 0.0106 - val_loss: 5.7645e-05 - val_mae: 0.0059\n",
      "Epoch 83/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0021 - mae: 0.0262 - val_loss: 1.2049e-04 - val_mae: 0.0085\n",
      "Epoch 84/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.3945e-05 - mae: 0.0051 - val_loss: 7.3250e-04 - val_mae: 0.0207\n",
      "Epoch 85/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 4.1352e-04 - mae: 0.0142 - val_loss: 3.2050e-05 - val_mae: 0.0043\n",
      "Epoch 86/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0205 - val_loss: 8.4716e-05 - val_mae: 0.0067\n",
      "Epoch 87/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 7.8833e-04 - mae: 0.0185 - val_loss: 5.8426e-04 - val_mae: 0.0187\n",
      "Epoch 88/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0974e-04 - mae: 0.0068 - val_loss: 9.3546e-05 - val_mae: 0.0076\n",
      "Epoch 89/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0239 - val_loss: 3.2657e-05 - val_mae: 0.0044\n",
      "Epoch 90/90\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 2.4609e-04 - mae: 0.0109 - val_loss: 7.3463e-04 - val_mae: 0.0208\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Train MSE: 5978335002.270826, Train MAE: 59400.88539014282\n",
      "Test MSE: 5997282150.096391, Test MAE: 59811.66618027343\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] Waiting for the remaining 15 operations to synchronize with Neptune. Do not kill this process.\n",
      "[neptune] [info   ] All 15 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-72/metadata\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"kulikovka/paris-boston-test\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiNjZjNWE3OS1jMzRlLTQyZjAtYmFiNi04ZGU1ZjY0MDAxNzgifQ==\"\n",
    ")\n",
    "\n",
    "space_sequential = {\n",
    "    'n_layers': hp.quniform('n_layers', 2, 6, 1),\n",
    "    'neurons': [hp.quniform(f'neurons_l{i}', 12, 64, 6) for i in range(6)],\n",
    "    'activations': [hp.choice(f'activation_l{i}', ['relu', 'leaky_relu']) for i in range(6)],\n",
    "    'lr': hp.loguniform('lr', np.log(1e-5), np.log(1e-1)),\n",
    "    'batch_size': hp.choice('batch_size', [10,16, 32, 64]),\n",
    "    'epochs': hp.quniform('epochs', 50, 100, 10),\n",
    "    'optimizer': hp.choice('optimizer', ['Adam', 'SGD', 'RMSprop', 'Adagrad'])\n",
    "}\n",
    "\n",
    "def build_model_paris(params):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(15,)))\n",
    "    n_layers = int(params['n_layers'])\n",
    "    for i in range(n_layers):\n",
    "        model.add(Dense(int(params['neurons'][i]), activation=params['activations'][i]))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    if params['optimizer'] == 'Adam':\n",
    "        opt = Adam(learning_rate=params['lr'])\n",
    "    elif params['optimizer'] == 'SGD':\n",
    "        opt = SGD(learning_rate=params['lr'])\n",
    "    elif params['optimizer'] == 'RMSprop':\n",
    "        opt = RMSprop(learning_rate=params['lr'])\n",
    "    else:\n",
    "        opt = Adagrad(learning_rate=params['lr'])\n",
    "\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def objective_sequential_paris(params):\n",
    "    model = build_model_paris(params)\n",
    "    model.fit(\n",
    "        X_train_pca_paris, y_train_paris,\n",
    "        epochs=int(params['epochs']),\n",
    "        batch_size=int(params['batch_size']),\n",
    "        verbose=0\n",
    "    )\n",
    "    test_loss, _ = model.evaluate(X_test_pca_paris, y_test_paris, verbose=0)\n",
    "    return {'loss': test_loss, 'status': STATUS_OK}\n",
    "\n",
    "trials = Trials()\n",
    "best_sequential_paris = fmin(\n",
    "    fn=objective_sequential_paris,\n",
    "    space=space_sequential,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=5,\n",
    "    trials=trials\n",
    ")\n",
    "\n",
    "best_params = {\n",
    "    'n_layers': int(best_sequential_paris['n_layers']),\n",
    "    'lr': best_sequential_paris['lr'],\n",
    "    'batch_size':  [10,16, 32, 64][best_sequential_paris['batch_size']],\n",
    "    'epochs': int(best_sequential_paris['epochs']),\n",
    "    'optimizer': ['Adam', 'SGD', 'RMSprop', 'Adagrad'][best_sequential_paris['optimizer']],\n",
    "    'neurons': [],\n",
    "    'activations': []\n",
    "}\n",
    "\n",
    "for i in range(best_params['n_layers']):\n",
    "    n_key = f'neurons_l{i}'\n",
    "    a_key = f'activation_l{i}'\n",
    "    if n_key in best_sequential_paris:\n",
    "        best_params['neurons'].append(int(best_sequential_paris[n_key]))\n",
    "    if a_key in best_sequential_paris:\n",
    "        best_params['activations'].append(['relu', 'leaky_relu'][best_sequential_paris[a_key]])\n",
    "\n",
    "for key, value in best_params.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "final_model = build_model_paris(best_params)\n",
    "history = final_model.fit(\n",
    "    X_train_pca_paris, y_train_paris,\n",
    "    epochs=best_params['epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    verbose=1,\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "y_train_pred_scaled = final_model.predict(X_train_pca_paris)\n",
    "y_test_pred_scaled = final_model.predict(X_test_pca_paris)\n",
    "\n",
    "y_train_pred = y_scaler.inverse_transform(y_train_pred_scaled)\n",
    "y_test_pred = y_scaler.inverse_transform(y_test_pred_scaled)\n",
    "y_train_real = y_scaler.inverse_transform(y_train_paris)\n",
    "y_test_real = y_scaler.inverse_transform(y_test_paris)\n",
    "\n",
    "\n",
    "train_mse_real = mean_squared_error(y_train_real, y_train_pred)\n",
    "train_mae_real = mean_absolute_error(y_train_real, y_train_pred)\n",
    "test_mse_real = mean_squared_error(y_test_real, y_test_pred)\n",
    "test_mae_real = mean_absolute_error(y_test_real, y_test_pred)\n",
    "\n",
    "print(f\"Train MSE: {train_mse_real}, Train MAE: {train_mae_real}\")\n",
    "print(f\"Test MSE: {test_mse_real}, Test MAE: {test_mae_real}\")\n",
    "\n",
    "\n",
    "\n",
    "run[\"best_params/n_layers\"] = best_params['n_layers']\n",
    "run[\"best_params/lr\"] = best_params['lr']\n",
    "run[\"best_params/batch_size\"] = best_params['batch_size']\n",
    "run[\"best_params/epochs\"] = best_params['epochs']\n",
    "run[\"best_params/optimizer\"] = best_params['optimizer']\n",
    "\n",
    "for i in range(best_params['n_layers']):\n",
    "    run[f\"best_params/layer_{i+1}/neurons\"] = best_params['neurons'][i]\n",
    "    run[f\"best_params/layer_{i+1}/activation\"] = best_params['activations'][i]\n",
    "\n",
    "run[\"final_metrics/train_mse\"] = train_mse_real\n",
    "run[\"final_metrics/train_mae\"] = train_mae_real\n",
    "run[\"final_metrics/test_mse\"] = test_mse_real\n",
    "run[\"final_metrics/test_mae\"] = test_mae_real\n",
    "\n",
    "run.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "efc11bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[neptune] [info   ] Neptune initialized. Open in the app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-24 17:25:58,319] A new study created in memory with name: no-name-4e8c204b-341a-4d78-8df6-f4ec9dd1368b\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938cfd58d9364875a2b60ffe78916dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0784 - mae: 0.1855 - val_loss: 0.0219 - val_mae: 0.1183\n",
      "Epoch 2/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0194 - mae: 0.1118 - val_loss: 0.0175 - val_mae: 0.1082\n",
      "Epoch 3/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0165 - mae: 0.1033 - val_loss: 0.0158 - val_mae: 0.1015\n",
      "Epoch 4/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0153 - mae: 0.0992 - val_loss: 0.0153 - val_mae: 0.1006\n",
      "Epoch 5/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0145 - mae: 0.0966 - val_loss: 0.0150 - val_mae: 0.0991\n",
      "Epoch 6/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0949 - val_loss: 0.0148 - val_mae: 0.0973\n",
      "Epoch 7/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0136 - mae: 0.0938 - val_loss: 0.0147 - val_mae: 0.0979\n",
      "Epoch 8/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0134 - mae: 0.0926 - val_loss: 0.0139 - val_mae: 0.0957\n",
      "Epoch 9/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0131 - mae: 0.0915 - val_loss: 0.0152 - val_mae: 0.0999\n",
      "Epoch 10/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0129 - mae: 0.0908 - val_loss: 0.0137 - val_mae: 0.0947\n",
      "Epoch 11/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0126 - mae: 0.0896 - val_loss: 0.0145 - val_mae: 0.0973\n",
      "Epoch 12/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0125 - mae: 0.0891 - val_loss: 0.0157 - val_mae: 0.1010\n",
      "Epoch 13/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0122 - mae: 0.0882 - val_loss: 0.0133 - val_mae: 0.0931\n",
      "Epoch 14/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0121 - mae: 0.0875 - val_loss: 0.0131 - val_mae: 0.0919\n",
      "Epoch 15/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119 - mae: 0.0864 - val_loss: 0.0136 - val_mae: 0.0937\n",
      "Epoch 16/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0117 - mae: 0.0854 - val_loss: 0.0129 - val_mae: 0.0904\n",
      "Epoch 17/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0116 - mae: 0.0846 - val_loss: 0.0126 - val_mae: 0.0895\n",
      "Epoch 18/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0114 - mae: 0.0836 - val_loss: 0.0131 - val_mae: 0.0910\n",
      "Epoch 19/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0112 - mae: 0.0826 - val_loss: 0.0123 - val_mae: 0.0881\n",
      "Epoch 20/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0110 - mae: 0.0818 - val_loss: 0.0121 - val_mae: 0.0870\n",
      "Epoch 21/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0108 - mae: 0.0806 - val_loss: 0.0120 - val_mae: 0.0867\n",
      "Epoch 22/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0105 - mae: 0.0793 - val_loss: 0.0119 - val_mae: 0.0858\n",
      "Epoch 23/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0103 - mae: 0.0782 - val_loss: 0.0120 - val_mae: 0.0857\n",
      "Epoch 24/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0101 - mae: 0.0772 - val_loss: 0.0112 - val_mae: 0.0823\n",
      "Epoch 25/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0099 - mae: 0.0756 - val_loss: 0.0107 - val_mae: 0.0804\n",
      "Epoch 26/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0095 - mae: 0.0739 - val_loss: 0.0107 - val_mae: 0.0794\n",
      "Epoch 27/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0093 - mae: 0.0723 - val_loss: 0.0103 - val_mae: 0.0772\n",
      "Epoch 28/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0090 - mae: 0.0705 - val_loss: 0.0096 - val_mae: 0.0735\n",
      "Epoch 29/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0087 - mae: 0.0684 - val_loss: 0.0097 - val_mae: 0.0745\n",
      "Epoch 30/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0085 - mae: 0.0673 - val_loss: 0.0091 - val_mae: 0.0708\n",
      "Epoch 31/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0082 - mae: 0.0654 - val_loss: 0.0089 - val_mae: 0.0699\n",
      "Epoch 32/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0639 - val_loss: 0.0088 - val_mae: 0.0691\n",
      "Epoch 33/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0629 - val_loss: 0.0087 - val_mae: 0.0679\n",
      "Epoch 34/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0616 - val_loss: 0.0083 - val_mae: 0.0662\n",
      "Epoch 35/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0075 - mae: 0.0608 - val_loss: 0.0083 - val_mae: 0.0648\n",
      "Epoch 36/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0600 - val_loss: 0.0086 - val_mae: 0.0658\n",
      "Epoch 37/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0073 - mae: 0.0590 - val_loss: 0.0080 - val_mae: 0.0621\n",
      "Epoch 38/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0580 - val_loss: 0.0080 - val_mae: 0.0631\n",
      "Epoch 39/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0576 - val_loss: 0.0080 - val_mae: 0.0624\n",
      "Epoch 40/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0571 - val_loss: 0.0078 - val_mae: 0.0604\n",
      "Epoch 41/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0070 - mae: 0.0563 - val_loss: 0.0076 - val_mae: 0.0598\n",
      "Epoch 42/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0556 - val_loss: 0.0075 - val_mae: 0.0586\n",
      "Epoch 43/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0553 - val_loss: 0.0081 - val_mae: 0.0628\n",
      "Epoch 44/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0547 - val_loss: 0.0078 - val_mae: 0.0594\n",
      "Epoch 45/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0545 - val_loss: 0.0074 - val_mae: 0.0577\n",
      "Epoch 46/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0066 - mae: 0.0538 - val_loss: 0.0080 - val_mae: 0.0614\n",
      "Epoch 47/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0066 - mae: 0.0531 - val_loss: 0.0076 - val_mae: 0.0577\n",
      "Epoch 48/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0066 - mae: 0.0532 - val_loss: 0.0074 - val_mae: 0.0569\n",
      "Epoch 49/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0066 - mae: 0.0527 - val_loss: 0.0073 - val_mae: 0.0563\n",
      "Epoch 50/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 0.0072 - val_mae: 0.0559\n",
      "Epoch 51/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0523 - val_loss: 0.0076 - val_mae: 0.0597\n",
      "Epoch 52/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0517 - val_loss: 0.0073 - val_mae: 0.0571\n",
      "Epoch 53/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 0.0071 - val_mae: 0.0547\n",
      "Epoch 54/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0512 - val_loss: 0.0074 - val_mae: 0.0566\n",
      "Epoch 55/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0508 - val_loss: 0.0073 - val_mae: 0.0551\n",
      "Epoch 56/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0507 - val_loss: 0.0070 - val_mae: 0.0538\n",
      "Epoch 57/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0504 - val_loss: 0.0071 - val_mae: 0.0536\n",
      "Epoch 58/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0502 - val_loss: 0.0071 - val_mae: 0.0547\n",
      "Epoch 59/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0500 - val_loss: 0.0071 - val_mae: 0.0539\n",
      "Epoch 60/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0496 - val_loss: 0.0072 - val_mae: 0.0544\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:27:08,392] Trial 0 finished with values: [51127772086.07805, 142949.22476122133] and parameters: {'n_layers': 4, 'lr': 0.03910604389215573, 'batch_size': 16, 'epochs': 60, 'optimizer': 'Adagrad', 'neurons_l0': 48, 'activation_l0': 'relu', 'neurons_l1': 16, 'activation_l1': 'leaky_relu', 'neurons_l2': 8, 'activation_l2': 'relu', 'neurons_l3': 40, 'activation_l3': 'relu'}.\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.1403 - mae: 0.2657 - val_loss: 0.0430 - val_mae: 0.1657\n",
      "Epoch 2/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0365 - mae: 0.1513 - val_loss: 0.0317 - val_mae: 0.1419\n",
      "Epoch 3/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0284 - mae: 0.1342 - val_loss: 0.0265 - val_mae: 0.1293\n",
      "Epoch 4/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1253 - val_loss: 0.0235 - val_mae: 0.1220\n",
      "Epoch 5/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0224 - mae: 0.1193 - val_loss: 0.0233 - val_mae: 0.1211\n",
      "Epoch 6/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0209 - mae: 0.1157 - val_loss: 0.0207 - val_mae: 0.1146\n",
      "Epoch 7/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0198 - mae: 0.1125 - val_loss: 0.0201 - val_mae: 0.1139\n",
      "Epoch 8/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0191 - mae: 0.1105 - val_loss: 0.0193 - val_mae: 0.1109\n",
      "Epoch 9/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0183 - mae: 0.1083 - val_loss: 0.0183 - val_mae: 0.1086\n",
      "Epoch 10/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0177 - mae: 0.1069 - val_loss: 0.0179 - val_mae: 0.1078\n",
      "Epoch 11/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0173 - mae: 0.1058 - val_loss: 0.0175 - val_mae: 0.1067\n",
      "Epoch 12/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0170 - mae: 0.1047 - val_loss: 0.0173 - val_mae: 0.1050\n",
      "Epoch 13/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0166 - mae: 0.1036 - val_loss: 0.0168 - val_mae: 0.1039\n",
      "Epoch 14/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0163 - mae: 0.1028 - val_loss: 0.0170 - val_mae: 0.1042\n",
      "Epoch 15/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0160 - mae: 0.1020 - val_loss: 0.0165 - val_mae: 0.1025\n",
      "Epoch 16/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0158 - mae: 0.1012 - val_loss: 0.0164 - val_mae: 0.1031\n",
      "Epoch 17/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0156 - mae: 0.1007 - val_loss: 0.0162 - val_mae: 0.1021\n",
      "Epoch 18/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0154 - mae: 0.1001 - val_loss: 0.0160 - val_mae: 0.1011\n",
      "Epoch 19/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0152 - mae: 0.0994 - val_loss: 0.0159 - val_mae: 0.1011\n",
      "Epoch 20/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0151 - mae: 0.0989 - val_loss: 0.0158 - val_mae: 0.1006\n",
      "Epoch 21/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0149 - mae: 0.0984 - val_loss: 0.0158 - val_mae: 0.1003\n",
      "Epoch 22/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0148 - mae: 0.0981 - val_loss: 0.0156 - val_mae: 0.1006\n",
      "Epoch 23/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0147 - mae: 0.0976 - val_loss: 0.0154 - val_mae: 0.0992\n",
      "Epoch 24/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0146 - mae: 0.0971 - val_loss: 0.0156 - val_mae: 0.1008\n",
      "Epoch 25/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0145 - mae: 0.0969 - val_loss: 0.0154 - val_mae: 0.0995\n",
      "Epoch 26/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0144 - mae: 0.0965 - val_loss: 0.0152 - val_mae: 0.0984\n",
      "Epoch 27/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0143 - mae: 0.0962 - val_loss: 0.0151 - val_mae: 0.0988\n",
      "Epoch 28/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0142 - mae: 0.0958 - val_loss: 0.0151 - val_mae: 0.0977\n",
      "Epoch 29/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0141 - mae: 0.0956 - val_loss: 0.0150 - val_mae: 0.0981\n",
      "Epoch 30/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0952 - val_loss: 0.0149 - val_mae: 0.0984\n",
      "Epoch 31/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0139 - mae: 0.0949 - val_loss: 0.0154 - val_mae: 0.1002\n",
      "Epoch 32/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0139 - mae: 0.0949 - val_loss: 0.0149 - val_mae: 0.0985\n",
      "Epoch 33/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0138 - mae: 0.0945 - val_loss: 0.0151 - val_mae: 0.0994\n",
      "Epoch 34/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0137 - mae: 0.0942 - val_loss: 0.0147 - val_mae: 0.0974\n",
      "Epoch 35/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0137 - mae: 0.0943 - val_loss: 0.0146 - val_mae: 0.0968\n",
      "Epoch 36/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0136 - mae: 0.0937 - val_loss: 0.0146 - val_mae: 0.0966\n",
      "Epoch 37/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0136 - mae: 0.0937 - val_loss: 0.0146 - val_mae: 0.0966\n",
      "Epoch 38/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0135 - mae: 0.0936 - val_loss: 0.0147 - val_mae: 0.0980\n",
      "Epoch 39/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0146 - val_mae: 0.0965\n",
      "Epoch 40/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0134 - mae: 0.0932 - val_loss: 0.0147 - val_mae: 0.0966\n",
      "Epoch 41/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0929 - val_loss: 0.0144 - val_mae: 0.0968\n",
      "Epoch 42/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0925 - val_loss: 0.0143 - val_mae: 0.0954\n",
      "Epoch 43/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0926 - val_loss: 0.0144 - val_mae: 0.0963\n",
      "Epoch 44/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0132 - mae: 0.0924 - val_loss: 0.0150 - val_mae: 0.0998\n",
      "Epoch 45/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0923 - val_loss: 0.0143 - val_mae: 0.0959\n",
      "Epoch 46/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0921 - val_loss: 0.0144 - val_mae: 0.0959\n",
      "Epoch 47/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0131 - mae: 0.0919 - val_loss: 0.0144 - val_mae: 0.0962\n",
      "Epoch 48/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0130 - mae: 0.0918 - val_loss: 0.0142 - val_mae: 0.0960\n",
      "Epoch 49/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0130 - mae: 0.0918 - val_loss: 0.0145 - val_mae: 0.0964\n",
      "Epoch 50/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0129 - mae: 0.0916 - val_loss: 0.0140 - val_mae: 0.0949\n",
      "Epoch 51/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0129 - mae: 0.0914 - val_loss: 0.0143 - val_mae: 0.0965\n",
      "Epoch 52/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0129 - mae: 0.0914 - val_loss: 0.0144 - val_mae: 0.0953\n",
      "Epoch 53/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0128 - mae: 0.0911 - val_loss: 0.0141 - val_mae: 0.0947\n",
      "Epoch 54/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0128 - mae: 0.0908 - val_loss: 0.0139 - val_mae: 0.0948\n",
      "Epoch 55/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0908 - val_loss: 0.0139 - val_mae: 0.0943\n",
      "Epoch 56/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0909 - val_loss: 0.0144 - val_mae: 0.0960\n",
      "Epoch 57/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0906 - val_loss: 0.0140 - val_mae: 0.0950\n",
      "Epoch 58/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0906 - val_loss: 0.0139 - val_mae: 0.0944\n",
      "Epoch 59/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0904 - val_loss: 0.0140 - val_mae: 0.0949\n",
      "Epoch 60/60\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0126 - mae: 0.0904 - val_loss: 0.0139 - val_mae: 0.0937\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "[I 2025-10-24 17:29:02,359] Trial 1 finished with values: [104660325237.1061, 259791.50043818663] and parameters: {'n_layers': 6, 'lr': 0.00819841747911116, 'batch_size': 10, 'epochs': 60, 'optimizer': 'Adagrad', 'neurons_l0': 48, 'activation_l0': 'relu', 'neurons_l1': 8, 'activation_l1': 'leaky_relu', 'neurons_l2': 16, 'activation_l2': 'relu', 'neurons_l3': 48, 'activation_l3': 'leaky_relu', 'neurons_l4': 40, 'activation_l4': 'leaky_relu', 'neurons_l5': 48, 'activation_l5': 'relu'}.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1.1955 - mae: 0.9229 - val_loss: 1.2474 - val_mae: 0.9358\n",
      "Epoch 2/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1881 - mae: 0.9203 - val_loss: 1.2412 - val_mae: 0.9337\n",
      "Epoch 3/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1831 - mae: 0.9186 - val_loss: 1.2365 - val_mae: 0.9321\n",
      "Epoch 4/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1791 - mae: 0.9172 - val_loss: 1.2326 - val_mae: 0.9308\n",
      "Epoch 5/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1756 - mae: 0.9160 - val_loss: 1.2292 - val_mae: 0.9296\n",
      "Epoch 6/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1726 - mae: 0.9149 - val_loss: 1.2261 - val_mae: 0.9286\n",
      "Epoch 7/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1698 - mae: 0.9139 - val_loss: 1.2232 - val_mae: 0.9276\n",
      "Epoch 8/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1673 - mae: 0.9130 - val_loss: 1.2206 - val_mae: 0.9267\n",
      "Epoch 9/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1649 - mae: 0.9122 - val_loss: 1.2182 - val_mae: 0.9259\n",
      "Epoch 10/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1627 - mae: 0.9114 - val_loss: 1.2159 - val_mae: 0.9251\n",
      "Epoch 11/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1606 - mae: 0.9107 - val_loss: 1.2137 - val_mae: 0.9244\n",
      "Epoch 12/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1587 - mae: 0.9099 - val_loss: 1.2117 - val_mae: 0.9237\n",
      "Epoch 13/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1568 - mae: 0.9093 - val_loss: 1.2097 - val_mae: 0.9230\n",
      "Epoch 14/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1550 - mae: 0.9086 - val_loss: 1.2078 - val_mae: 0.9224\n",
      "Epoch 15/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1532 - mae: 0.9080 - val_loss: 1.2060 - val_mae: 0.9218\n",
      "Epoch 16/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1516 - mae: 0.9074 - val_loss: 1.2042 - val_mae: 0.9212\n",
      "Epoch 17/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1500 - mae: 0.9068 - val_loss: 1.2026 - val_mae: 0.9206\n",
      "Epoch 18/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1484 - mae: 0.9063 - val_loss: 1.2009 - val_mae: 0.9201\n",
      "Epoch 19/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1470 - mae: 0.9057 - val_loss: 1.1994 - val_mae: 0.9195\n",
      "Epoch 20/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1455 - mae: 0.9052 - val_loss: 1.1978 - val_mae: 0.9190\n",
      "Epoch 21/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1441 - mae: 0.9047 - val_loss: 1.1963 - val_mae: 0.9185\n",
      "Epoch 22/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1427 - mae: 0.9042 - val_loss: 1.1949 - val_mae: 0.9180\n",
      "Epoch 23/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1414 - mae: 0.9037 - val_loss: 1.1935 - val_mae: 0.9176\n",
      "Epoch 24/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1401 - mae: 0.9033 - val_loss: 1.1921 - val_mae: 0.9171\n",
      "Epoch 25/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1389 - mae: 0.9028 - val_loss: 1.1908 - val_mae: 0.9166\n",
      "Epoch 26/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1376 - mae: 0.9024 - val_loss: 1.1895 - val_mae: 0.9162\n",
      "Epoch 27/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1364 - mae: 0.9019 - val_loss: 1.1882 - val_mae: 0.9157\n",
      "Epoch 28/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1353 - mae: 0.9015 - val_loss: 1.1870 - val_mae: 0.9153\n",
      "Epoch 29/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1341 - mae: 0.9011 - val_loss: 1.1857 - val_mae: 0.9149\n",
      "Epoch 30/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1330 - mae: 0.9007 - val_loss: 1.1845 - val_mae: 0.9145\n",
      "Epoch 31/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1319 - mae: 0.9003 - val_loss: 1.1834 - val_mae: 0.9141\n",
      "Epoch 32/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1308 - mae: 0.8999 - val_loss: 1.1822 - val_mae: 0.9137\n",
      "Epoch 33/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1297 - mae: 0.8995 - val_loss: 1.1811 - val_mae: 0.9133\n",
      "Epoch 34/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1287 - mae: 0.8991 - val_loss: 1.1800 - val_mae: 0.9129\n",
      "Epoch 35/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1277 - mae: 0.8987 - val_loss: 1.1789 - val_mae: 0.9125\n",
      "Epoch 36/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1267 - mae: 0.8983 - val_loss: 1.1778 - val_mae: 0.9122\n",
      "Epoch 37/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1257 - mae: 0.8980 - val_loss: 1.1768 - val_mae: 0.9118\n",
      "Epoch 38/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1247 - mae: 0.8976 - val_loss: 1.1757 - val_mae: 0.9115\n",
      "Epoch 39/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1237 - mae: 0.8973 - val_loss: 1.1747 - val_mae: 0.9111\n",
      "Epoch 40/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1228 - mae: 0.8969 - val_loss: 1.1737 - val_mae: 0.9108\n",
      "Epoch 41/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1219 - mae: 0.8966 - val_loss: 1.1727 - val_mae: 0.9104\n",
      "Epoch 42/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1210 - mae: 0.8962 - val_loss: 1.1718 - val_mae: 0.9101\n",
      "Epoch 43/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1201 - mae: 0.8959 - val_loss: 1.1708 - val_mae: 0.9098\n",
      "Epoch 44/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1192 - mae: 0.8956 - val_loss: 1.1698 - val_mae: 0.9094\n",
      "Epoch 45/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1183 - mae: 0.8953 - val_loss: 1.1689 - val_mae: 0.9091\n",
      "Epoch 46/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1174 - mae: 0.8949 - val_loss: 1.1680 - val_mae: 0.9088\n",
      "Epoch 47/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1166 - mae: 0.8946 - val_loss: 1.1671 - val_mae: 0.9085\n",
      "Epoch 48/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1158 - mae: 0.8943 - val_loss: 1.1662 - val_mae: 0.9082\n",
      "Epoch 49/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1149 - mae: 0.8940 - val_loss: 1.1653 - val_mae: 0.9079\n",
      "Epoch 50/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1141 - mae: 0.8937 - val_loss: 1.1644 - val_mae: 0.9076\n",
      "Epoch 51/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1133 - mae: 0.8934 - val_loss: 1.1636 - val_mae: 0.9073\n",
      "Epoch 52/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1125 - mae: 0.8931 - val_loss: 1.1627 - val_mae: 0.9070\n",
      "Epoch 53/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1117 - mae: 0.8928 - val_loss: 1.1619 - val_mae: 0.9067\n",
      "Epoch 54/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1109 - mae: 0.8925 - val_loss: 1.1611 - val_mae: 0.9064\n",
      "Epoch 55/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1102 - mae: 0.8923 - val_loss: 1.1602 - val_mae: 0.9061\n",
      "Epoch 56/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1094 - mae: 0.8920 - val_loss: 1.1594 - val_mae: 0.9058\n",
      "Epoch 57/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1087 - mae: 0.8917 - val_loss: 1.1586 - val_mae: 0.9055\n",
      "Epoch 58/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1079 - mae: 0.8914 - val_loss: 1.1578 - val_mae: 0.9053\n",
      "Epoch 59/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1072 - mae: 0.8911 - val_loss: 1.1571 - val_mae: 0.9050\n",
      "Epoch 60/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.1065 - mae: 0.8909 - val_loss: 1.1563 - val_mae: 0.9047\n",
      "Epoch 61/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1057 - mae: 0.8906 - val_loss: 1.1555 - val_mae: 0.9045\n",
      "Epoch 62/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1050 - mae: 0.8903 - val_loss: 1.1548 - val_mae: 0.9042\n",
      "Epoch 63/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1043 - mae: 0.8901 - val_loss: 1.1540 - val_mae: 0.9039\n",
      "Epoch 64/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1036 - mae: 0.8898 - val_loss: 1.1533 - val_mae: 0.9037\n",
      "Epoch 65/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1029 - mae: 0.8896 - val_loss: 1.1525 - val_mae: 0.9034\n",
      "Epoch 66/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1023 - mae: 0.8893 - val_loss: 1.1518 - val_mae: 0.9032\n",
      "Epoch 67/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1016 - mae: 0.8891 - val_loss: 1.1511 - val_mae: 0.9029\n",
      "Epoch 68/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1009 - mae: 0.8888 - val_loss: 1.1504 - val_mae: 0.9027\n",
      "Epoch 69/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.1003 - mae: 0.8886 - val_loss: 1.1497 - val_mae: 0.9024\n",
      "Epoch 70/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0996 - mae: 0.8883 - val_loss: 1.1490 - val_mae: 0.9022\n",
      "Epoch 71/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0990 - mae: 0.8881 - val_loss: 1.1483 - val_mae: 0.9020\n",
      "Epoch 72/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0983 - mae: 0.8878 - val_loss: 1.1476 - val_mae: 0.9017\n",
      "Epoch 73/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0977 - mae: 0.8876 - val_loss: 1.1469 - val_mae: 0.9015\n",
      "Epoch 74/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0970 - mae: 0.8873 - val_loss: 1.1462 - val_mae: 0.9013\n",
      "Epoch 75/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0964 - mae: 0.8871 - val_loss: 1.1455 - val_mae: 0.9010\n",
      "Epoch 76/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0958 - mae: 0.8869 - val_loss: 1.1449 - val_mae: 0.9008\n",
      "Epoch 77/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0952 - mae: 0.8866 - val_loss: 1.1442 - val_mae: 0.9006\n",
      "Epoch 78/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0946 - mae: 0.8864 - val_loss: 1.1436 - val_mae: 0.9003\n",
      "Epoch 79/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0939 - mae: 0.8862 - val_loss: 1.1429 - val_mae: 0.9001\n",
      "Epoch 80/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0933 - mae: 0.8860 - val_loss: 1.1423 - val_mae: 0.8999\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:29:48,948] Trial 2 finished with values: [9089783367712.89, 2552844.76218125] and parameters: {'n_layers': 3, 'lr': 1.3694307896766773e-05, 'batch_size': 32, 'epochs': 80, 'optimizer': 'Adagrad', 'neurons_l0': 24, 'activation_l0': 'leaky_relu', 'neurons_l1': 16, 'activation_l1': 'leaky_relu', 'neurons_l2': 40, 'activation_l2': 'leaky_relu'}.\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.9377 - mae: 0.8317 - val_loss: 0.8995 - val_mae: 0.8086\n",
      "Epoch 2/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8490 - mae: 0.7861 - val_loss: 0.7857 - val_mae: 0.7466\n",
      "Epoch 3/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7279 - mae: 0.7179 - val_loss: 0.6477 - val_mae: 0.6662\n",
      "Epoch 4/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5948 - mae: 0.6389 - val_loss: 0.5143 - val_mae: 0.5864\n",
      "Epoch 5/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4667 - mae: 0.5586 - val_loss: 0.3936 - val_mae: 0.5107\n",
      "Epoch 6/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3553 - mae: 0.4835 - val_loss: 0.2973 - val_mae: 0.4431\n",
      "Epoch 7/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.2712 - mae: 0.4194 - val_loss: 0.2310 - val_mae: 0.3903\n",
      "Epoch 8/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.2147 - mae: 0.3719 - val_loss: 0.1868 - val_mae: 0.3497\n",
      "Epoch 9/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1782 - mae: 0.3380 - val_loss: 0.1581 - val_mae: 0.3220\n",
      "Epoch 10/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1532 - mae: 0.3128 - val_loss: 0.1371 - val_mae: 0.3006\n",
      "Epoch 11/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1350 - mae: 0.2931 - val_loss: 0.1217 - val_mae: 0.2834\n",
      "Epoch 12/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1208 - mae: 0.2770 - val_loss: 0.1100 - val_mae: 0.2697\n",
      "Epoch 13/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1094 - mae: 0.2638 - val_loss: 0.1001 - val_mae: 0.2571\n",
      "Epoch 14/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1001 - mae: 0.2522 - val_loss: 0.0924 - val_mae: 0.2466\n",
      "Epoch 15/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0923 - mae: 0.2417 - val_loss: 0.0849 - val_mae: 0.2361\n",
      "Epoch 16/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0854 - mae: 0.2326 - val_loss: 0.0791 - val_mae: 0.2278\n",
      "Epoch 17/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0795 - mae: 0.2242 - val_loss: 0.0738 - val_mae: 0.2198\n",
      "Epoch 18/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0742 - mae: 0.2166 - val_loss: 0.0693 - val_mae: 0.2126\n",
      "Epoch 19/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0698 - mae: 0.2100 - val_loss: 0.0655 - val_mae: 0.2068\n",
      "Epoch 20/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0658 - mae: 0.2037 - val_loss: 0.0617 - val_mae: 0.2002\n",
      "Epoch 21/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0622 - mae: 0.1981 - val_loss: 0.0589 - val_mae: 0.1955\n",
      "Epoch 22/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0590 - mae: 0.1929 - val_loss: 0.0559 - val_mae: 0.1896\n",
      "Epoch 23/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0562 - mae: 0.1884 - val_loss: 0.0532 - val_mae: 0.1849\n",
      "Epoch 24/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0536 - mae: 0.1838 - val_loss: 0.0509 - val_mae: 0.1805\n",
      "Epoch 25/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0513 - mae: 0.1799 - val_loss: 0.0491 - val_mae: 0.1768\n",
      "Epoch 26/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0493 - mae: 0.1763 - val_loss: 0.0474 - val_mae: 0.1733\n",
      "Epoch 27/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0474 - mae: 0.1730 - val_loss: 0.0458 - val_mae: 0.1700\n",
      "Epoch 28/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0456 - mae: 0.1695 - val_loss: 0.0437 - val_mae: 0.1651\n",
      "Epoch 29/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0441 - mae: 0.1669 - val_loss: 0.0427 - val_mae: 0.1629\n",
      "Epoch 30/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0427 - mae: 0.1643 - val_loss: 0.0416 - val_mae: 0.1608\n",
      "Epoch 31/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0414 - mae: 0.1616 - val_loss: 0.0402 - val_mae: 0.1577\n",
      "Epoch 32/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0402 - mae: 0.1594 - val_loss: 0.0395 - val_mae: 0.1566\n",
      "Epoch 33/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0391 - mae: 0.1571 - val_loss: 0.0382 - val_mae: 0.1538\n",
      "Epoch 34/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0380 - mae: 0.1550 - val_loss: 0.0373 - val_mae: 0.1521\n",
      "Epoch 35/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0371 - mae: 0.1531 - val_loss: 0.0365 - val_mae: 0.1496\n",
      "Epoch 36/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0362 - mae: 0.1513 - val_loss: 0.0359 - val_mae: 0.1484\n",
      "Epoch 37/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0353 - mae: 0.1493 - val_loss: 0.0349 - val_mae: 0.1467\n",
      "Epoch 38/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0345 - mae: 0.1477 - val_loss: 0.0340 - val_mae: 0.1448\n",
      "Epoch 39/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0338 - mae: 0.1462 - val_loss: 0.0337 - val_mae: 0.1438\n",
      "Epoch 40/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0330 - mae: 0.1447 - val_loss: 0.0326 - val_mae: 0.1414\n",
      "Epoch 41/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0323 - mae: 0.1431 - val_loss: 0.0323 - val_mae: 0.1409\n",
      "Epoch 42/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0317 - mae: 0.1416 - val_loss: 0.0318 - val_mae: 0.1394\n",
      "Epoch 43/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - mae: 0.1402 - val_loss: 0.0312 - val_mae: 0.1382\n",
      "Epoch 44/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0304 - mae: 0.1390 - val_loss: 0.0304 - val_mae: 0.1362\n",
      "Epoch 45/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0299 - mae: 0.1376 - val_loss: 0.0300 - val_mae: 0.1361\n",
      "Epoch 46/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0294 - mae: 0.1364 - val_loss: 0.0294 - val_mae: 0.1346\n",
      "Epoch 47/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0288 - mae: 0.1352 - val_loss: 0.0289 - val_mae: 0.1334\n",
      "Epoch 48/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0283 - mae: 0.1338 - val_loss: 0.0284 - val_mae: 0.1324\n",
      "Epoch 49/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0278 - mae: 0.1329 - val_loss: 0.0278 - val_mae: 0.1307\n",
      "Epoch 50/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0273 - mae: 0.1317 - val_loss: 0.0275 - val_mae: 0.1304\n",
      "Epoch 51/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0269 - mae: 0.1305 - val_loss: 0.0273 - val_mae: 0.1292\n",
      "Epoch 52/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0265 - mae: 0.1296 - val_loss: 0.0268 - val_mae: 0.1286\n",
      "Epoch 53/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0260 - mae: 0.1283 - val_loss: 0.0265 - val_mae: 0.1280\n",
      "Epoch 54/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0256 - mae: 0.1276 - val_loss: 0.0262 - val_mae: 0.1278\n",
      "Epoch 55/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0252 - mae: 0.1266 - val_loss: 0.0257 - val_mae: 0.1260\n",
      "Epoch 56/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0249 - mae: 0.1258 - val_loss: 0.0257 - val_mae: 0.1264\n",
      "Epoch 57/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0246 - mae: 0.1251 - val_loss: 0.0253 - val_mae: 0.1252\n",
      "Epoch 58/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0243 - mae: 0.1243 - val_loss: 0.0248 - val_mae: 0.1240\n",
      "Epoch 59/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0239 - mae: 0.1232 - val_loss: 0.0246 - val_mae: 0.1234\n",
      "Epoch 60/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0236 - mae: 0.1223 - val_loss: 0.0242 - val_mae: 0.1225\n",
      "Epoch 61/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0233 - mae: 0.1218 - val_loss: 0.0243 - val_mae: 0.1223\n",
      "Epoch 62/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0229 - mae: 0.1209 - val_loss: 0.0237 - val_mae: 0.1215\n",
      "Epoch 63/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0227 - mae: 0.1203 - val_loss: 0.0235 - val_mae: 0.1205\n",
      "Epoch 64/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0224 - mae: 0.1196 - val_loss: 0.0232 - val_mae: 0.1201\n",
      "Epoch 65/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0221 - mae: 0.1187 - val_loss: 0.0229 - val_mae: 0.1196\n",
      "Epoch 66/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0218 - mae: 0.1180 - val_loss: 0.0227 - val_mae: 0.1192\n",
      "Epoch 67/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0217 - mae: 0.1175 - val_loss: 0.0224 - val_mae: 0.1182\n",
      "Epoch 68/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0213 - mae: 0.1166 - val_loss: 0.0226 - val_mae: 0.1185\n",
      "Epoch 69/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0211 - mae: 0.1159 - val_loss: 0.0220 - val_mae: 0.1172\n",
      "Epoch 70/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0209 - mae: 0.1154 - val_loss: 0.0220 - val_mae: 0.1174\n",
      "Epoch 71/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0207 - mae: 0.1148 - val_loss: 0.0217 - val_mae: 0.1164\n",
      "Epoch 72/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0204 - mae: 0.1141 - val_loss: 0.0213 - val_mae: 0.1155\n",
      "Epoch 73/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0202 - mae: 0.1136 - val_loss: 0.0214 - val_mae: 0.1165\n",
      "Epoch 74/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - mae: 0.1133 - val_loss: 0.0211 - val_mae: 0.1147\n",
      "Epoch 75/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0199 - mae: 0.1126 - val_loss: 0.0209 - val_mae: 0.1145\n",
      "Epoch 76/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0196 - mae: 0.1118 - val_loss: 0.0208 - val_mae: 0.1148\n",
      "Epoch 77/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0195 - mae: 0.1114 - val_loss: 0.0205 - val_mae: 0.1137\n",
      "Epoch 78/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0192 - mae: 0.1107 - val_loss: 0.0209 - val_mae: 0.1146\n",
      "Epoch 79/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0191 - mae: 0.1103 - val_loss: 0.0202 - val_mae: 0.1128\n",
      "Epoch 80/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0190 - mae: 0.1098 - val_loss: 0.0201 - val_mae: 0.1126\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "[I 2025-10-24 17:30:26,143] Trial 3 finished with values: [155781229296.09476, 314895.4545224018] and parameters: {'n_layers': 6, 'lr': 5.216487843766715e-05, 'batch_size': 64, 'epochs': 80, 'optimizer': 'Adam', 'neurons_l0': 24, 'activation_l0': 'leaky_relu', 'neurons_l1': 48, 'activation_l1': 'relu', 'neurons_l2': 8, 'activation_l2': 'relu', 'neurons_l3': 8, 'activation_l3': 'leaky_relu', 'neurons_l4': 32, 'activation_l4': 'leaky_relu', 'neurons_l5': 40, 'activation_l5': 'relu'}.\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.6343 - mae: 0.6469 - val_loss: 0.2339 - val_mae: 0.3823\n",
      "Epoch 2/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.1201 - mae: 0.2706 - val_loss: 0.0658 - val_mae: 0.2013\n",
      "Epoch 3/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0472 - mae: 0.1711 - val_loss: 0.0332 - val_mae: 0.1456\n",
      "Epoch 4/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0274 - mae: 0.1317 - val_loss: 0.0245 - val_mae: 0.1259\n",
      "Epoch 5/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0212 - mae: 0.1158 - val_loss: 0.0196 - val_mae: 0.1113\n",
      "Epoch 6/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0182 - mae: 0.1079 - val_loss: 0.0180 - val_mae: 0.1054\n",
      "Epoch 7/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0167 - mae: 0.1034 - val_loss: 0.0181 - val_mae: 0.1077\n",
      "Epoch 8/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0158 - mae: 0.1007 - val_loss: 0.0166 - val_mae: 0.1025\n",
      "Epoch 9/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - mae: 0.0981 - val_loss: 0.0152 - val_mae: 0.0982\n",
      "Epoch 10/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0144 - mae: 0.0964 - val_loss: 0.0146 - val_mae: 0.0961\n",
      "Epoch 11/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0141 - mae: 0.0953 - val_loss: 0.0138 - val_mae: 0.0935\n",
      "Epoch 12/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0136 - mae: 0.0935 - val_loss: 0.0141 - val_mae: 0.0943\n",
      "Epoch 13/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0133 - mae: 0.0918 - val_loss: 0.0148 - val_mae: 0.0976\n",
      "Epoch 14/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0131 - mae: 0.0918 - val_loss: 0.0141 - val_mae: 0.0949\n",
      "Epoch 15/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0126 - mae: 0.0892 - val_loss: 0.0155 - val_mae: 0.1001\n",
      "Epoch 16/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0123 - mae: 0.0877 - val_loss: 0.0122 - val_mae: 0.0864\n",
      "Epoch 17/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0118 - mae: 0.0851 - val_loss: 0.0114 - val_mae: 0.0831\n",
      "Epoch 18/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0112 - mae: 0.0819 - val_loss: 0.0124 - val_mae: 0.0863\n",
      "Epoch 19/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0107 - mae: 0.0788 - val_loss: 0.0111 - val_mae: 0.0810\n",
      "Epoch 20/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0102 - mae: 0.0761 - val_loss: 0.0111 - val_mae: 0.0807\n",
      "Epoch 21/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0098 - mae: 0.0733 - val_loss: 0.0099 - val_mae: 0.0746\n",
      "Epoch 22/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0094 - mae: 0.0710 - val_loss: 0.0104 - val_mae: 0.0747\n",
      "Epoch 23/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0090 - mae: 0.0681 - val_loss: 0.0094 - val_mae: 0.0712\n",
      "Epoch 24/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0661 - val_loss: 0.0099 - val_mae: 0.0736\n",
      "Epoch 25/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0084 - mae: 0.0641 - val_loss: 0.0087 - val_mae: 0.0651\n",
      "Epoch 26/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0080 - mae: 0.0620 - val_loss: 0.0079 - val_mae: 0.0601\n",
      "Epoch 27/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0598 - val_loss: 0.0073 - val_mae: 0.0575\n",
      "Epoch 28/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0075 - mae: 0.0577 - val_loss: 0.0071 - val_mae: 0.0561\n",
      "Epoch 29/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0559 - val_loss: 0.0070 - val_mae: 0.0547\n",
      "Epoch 30/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0541 - val_loss: 0.0081 - val_mae: 0.0613\n",
      "Epoch 31/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0533 - val_loss: 0.0069 - val_mae: 0.0565\n",
      "Epoch 32/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0519 - val_loss: 0.0076 - val_mae: 0.0630\n",
      "Epoch 33/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0062 - mae: 0.0511 - val_loss: 0.0060 - val_mae: 0.0509\n",
      "Epoch 34/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0060 - mae: 0.0494 - val_loss: 0.0055 - val_mae: 0.0469\n",
      "Epoch 35/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0484 - val_loss: 0.0052 - val_mae: 0.0446\n",
      "Epoch 36/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0056 - mae: 0.0475 - val_loss: 0.0050 - val_mae: 0.0435\n",
      "Epoch 37/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0053 - mae: 0.0464 - val_loss: 0.0045 - val_mae: 0.0401\n",
      "Epoch 38/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0051 - mae: 0.0451 - val_loss: 0.0056 - val_mae: 0.0536\n",
      "Epoch 39/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0047 - mae: 0.0437 - val_loss: 0.0052 - val_mae: 0.0485\n",
      "Epoch 40/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0044 - mae: 0.0426 - val_loss: 0.0046 - val_mae: 0.0446\n",
      "Epoch 41/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0042 - mae: 0.0412 - val_loss: 0.0040 - val_mae: 0.0426\n",
      "Epoch 42/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0039 - mae: 0.0404 - val_loss: 0.0030 - val_mae: 0.0322\n",
      "Epoch 43/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0036 - mae: 0.0390 - val_loss: 0.0043 - val_mae: 0.0469\n",
      "Epoch 44/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0031 - mae: 0.0370 - val_loss: 0.0025 - val_mae: 0.0310\n",
      "Epoch 45/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0029 - mae: 0.0364 - val_loss: 0.0032 - val_mae: 0.0408\n",
      "Epoch 46/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0026 - mae: 0.0352 - val_loss: 0.0031 - val_mae: 0.0418\n",
      "Epoch 47/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0024 - mae: 0.0334 - val_loss: 0.0034 - val_mae: 0.0487\n",
      "Epoch 48/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0022 - mae: 0.0331 - val_loss: 0.0019 - val_mae: 0.0298\n",
      "Epoch 49/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0020 - mae: 0.0315 - val_loss: 0.0015 - val_mae: 0.0274\n",
      "Epoch 50/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0019 - mae: 0.0310 - val_loss: 0.0016 - val_mae: 0.0274\n",
      "Epoch 51/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0017 - mae: 0.0295 - val_loss: 0.0014 - val_mae: 0.0278\n",
      "Epoch 52/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0016 - mae: 0.0307 - val_loss: 0.0013 - val_mae: 0.0270\n",
      "Epoch 53/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0288 - val_loss: 0.0016 - val_mae: 0.0325\n",
      "Epoch 54/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0285 - val_loss: 0.0010 - val_mae: 0.0251\n",
      "Epoch 55/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0284 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 56/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0013 - mae: 0.0273 - val_loss: 5.7742e-04 - val_mae: 0.0169\n",
      "Epoch 57/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 6.1526e-04 - val_mae: 0.0180\n",
      "Epoch 58/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0264 - val_loss: 0.0017 - val_mae: 0.0342\n",
      "Epoch 59/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0255 - val_loss: 0.0041 - val_mae: 0.0557\n",
      "Epoch 60/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0011 - mae: 0.0253 - val_loss: 8.6534e-04 - val_mae: 0.0243\n",
      "Epoch 61/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0256 - val_loss: 0.0018 - val_mae: 0.0370\n",
      "Epoch 62/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0010 - mae: 0.0260 - val_loss: 0.0012 - val_mae: 0.0285\n",
      "Epoch 63/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8522e-04 - mae: 0.0245 - val_loss: 0.0026 - val_mae: 0.0437\n",
      "Epoch 64/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.9206e-04 - mae: 0.0250 - val_loss: 6.1085e-04 - val_mae: 0.0198\n",
      "Epoch 65/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.8344e-04 - mae: 0.0249 - val_loss: 3.5712e-04 - val_mae: 0.0139\n",
      "Epoch 66/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5118e-04 - mae: 0.0242 - val_loss: 6.7424e-04 - val_mae: 0.0214\n",
      "Epoch 67/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.2403e-04 - mae: 0.0241 - val_loss: 8.4543e-04 - val_mae: 0.0235\n",
      "Epoch 68/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.0763e-04 - mae: 0.0242 - val_loss: 0.0022 - val_mae: 0.0392\n",
      "Epoch 69/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.1543e-04 - mae: 0.0243 - val_loss: 6.6792e-04 - val_mae: 0.0212\n",
      "Epoch 70/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9827e-04 - mae: 0.0244 - val_loss: 5.8943e-04 - val_mae: 0.0194\n",
      "Epoch 71/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.8543e-04 - mae: 0.0233 - val_loss: 2.6974e-04 - val_mae: 0.0119\n",
      "Epoch 72/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.5972e-04 - mae: 0.0239 - val_loss: 0.0016 - val_mae: 0.0337\n",
      "Epoch 73/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.4536e-04 - mae: 0.0231 - val_loss: 5.1000e-04 - val_mae: 0.0182\n",
      "Epoch 74/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0994e-04 - mae: 0.0232 - val_loss: 7.3106e-04 - val_mae: 0.0211\n",
      "Epoch 75/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.1619e-04 - mae: 0.0232 - val_loss: 3.1133e-04 - val_mae: 0.0132\n",
      "Epoch 76/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.7054e-04 - mae: 0.0220 - val_loss: 3.0977e-04 - val_mae: 0.0139\n",
      "Epoch 77/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.8244e-04 - mae: 0.0221 - val_loss: 0.0013 - val_mae: 0.0313\n",
      "Epoch 78/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.0701e-04 - mae: 0.0226 - val_loss: 7.6245e-04 - val_mae: 0.0226\n",
      "Epoch 79/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7008e-04 - mae: 0.0221 - val_loss: 9.1171e-04 - val_mae: 0.0251\n",
      "Epoch 80/80\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 7.7811e-04 - mae: 0.0225 - val_loss: 4.7904e-04 - val_mae: 0.0181\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:30:52,289] Trial 4 finished with values: [3800032010.7040825, 50479.03112062682] and parameters: {'n_layers': 2, 'lr': 0.0011631743948867226, 'batch_size': 64, 'epochs': 80, 'optimizer': 'RMSprop', 'neurons_l0': 16, 'activation_l0': 'relu', 'neurons_l1': 40, 'activation_l1': 'relu'}.\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0857 - mae: 0.1983 - val_loss: 0.0185 - val_mae: 0.1105\n",
      "Epoch 2/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0224 - mae: 0.1192 - val_loss: 0.0165 - val_mae: 0.1029\n",
      "Epoch 3/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0186 - mae: 0.1091 - val_loss: 0.0143 - val_mae: 0.0974\n",
      "Epoch 4/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0169 - mae: 0.1039 - val_loss: 0.0181 - val_mae: 0.1089\n",
      "Epoch 5/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0161 - mae: 0.1009 - val_loss: 0.0138 - val_mae: 0.0940\n",
      "Epoch 6/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0157 - mae: 0.1003 - val_loss: 0.0164 - val_mae: 0.1022\n",
      "Epoch 7/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0149 - mae: 0.0976 - val_loss: 0.0175 - val_mae: 0.1080\n",
      "Epoch 8/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0148 - mae: 0.0969 - val_loss: 0.0152 - val_mae: 0.1001\n",
      "Epoch 9/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0144 - mae: 0.0960 - val_loss: 0.0127 - val_mae: 0.0905\n",
      "Epoch 10/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0142 - mae: 0.0952 - val_loss: 0.0136 - val_mae: 0.0924\n",
      "Epoch 11/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0960 - val_loss: 0.0127 - val_mae: 0.0904\n",
      "Epoch 12/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0143 - mae: 0.0956 - val_loss: 0.0135 - val_mae: 0.0944\n",
      "Epoch 13/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0139 - mae: 0.0945 - val_loss: 0.0154 - val_mae: 0.1005\n",
      "Epoch 14/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0135 - mae: 0.0932 - val_loss: 0.0140 - val_mae: 0.0939\n",
      "Epoch 15/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0140 - mae: 0.0947 - val_loss: 0.0122 - val_mae: 0.0887\n",
      "Epoch 16/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0137 - mae: 0.0936 - val_loss: 0.0124 - val_mae: 0.0891\n",
      "Epoch 17/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0132 - mae: 0.0918 - val_loss: 0.0123 - val_mae: 0.0886\n",
      "Epoch 18/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0136 - mae: 0.0930 - val_loss: 0.0134 - val_mae: 0.0940\n",
      "Epoch 19/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0132 - mae: 0.0918 - val_loss: 0.0121 - val_mae: 0.0886\n",
      "Epoch 20/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0134 - mae: 0.0926 - val_loss: 0.0132 - val_mae: 0.0930\n",
      "Epoch 21/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0128 - mae: 0.0906 - val_loss: 0.0145 - val_mae: 0.0980\n",
      "Epoch 22/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0129 - mae: 0.0908 - val_loss: 0.0143 - val_mae: 0.0953\n",
      "Epoch 23/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0131 - mae: 0.0914 - val_loss: 0.0122 - val_mae: 0.0889\n",
      "Epoch 24/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0129 - mae: 0.0908 - val_loss: 0.0118 - val_mae: 0.0882\n",
      "Epoch 25/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0126 - mae: 0.0898 - val_loss: 0.0127 - val_mae: 0.0894\n",
      "Epoch 26/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0897 - val_loss: 0.0126 - val_mae: 0.0903\n",
      "Epoch 27/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0126 - mae: 0.0898 - val_loss: 0.0123 - val_mae: 0.0890\n",
      "Epoch 28/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0125 - mae: 0.0892 - val_loss: 0.0130 - val_mae: 0.0919\n",
      "Epoch 29/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0891 - val_loss: 0.0136 - val_mae: 0.0918\n",
      "Epoch 30/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0889 - val_loss: 0.0120 - val_mae: 0.0877\n",
      "Epoch 31/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0880 - val_loss: 0.0123 - val_mae: 0.0878\n",
      "Epoch 32/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0888 - val_loss: 0.0127 - val_mae: 0.0899\n",
      "Epoch 33/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0124 - mae: 0.0892 - val_loss: 0.0119 - val_mae: 0.0879\n",
      "Epoch 34/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0122 - mae: 0.0879 - val_loss: 0.0119 - val_mae: 0.0871\n",
      "Epoch 35/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0122 - mae: 0.0881 - val_loss: 0.0128 - val_mae: 0.0889\n",
      "Epoch 36/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0120 - mae: 0.0874 - val_loss: 0.0124 - val_mae: 0.0895\n",
      "Epoch 37/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0120 - mae: 0.0874 - val_loss: 0.0123 - val_mae: 0.0891\n",
      "Epoch 38/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0120 - mae: 0.0876 - val_loss: 0.0120 - val_mae: 0.0879\n",
      "Epoch 39/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119 - mae: 0.0871 - val_loss: 0.0133 - val_mae: 0.0929\n",
      "Epoch 40/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119 - mae: 0.0864 - val_loss: 0.0150 - val_mae: 0.0966\n",
      "Epoch 41/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0866 - val_loss: 0.0122 - val_mae: 0.0877\n",
      "Epoch 42/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0866 - val_loss: 0.0129 - val_mae: 0.0897\n",
      "Epoch 43/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119 - mae: 0.0871 - val_loss: 0.0117 - val_mae: 0.0869\n",
      "Epoch 44/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0864 - val_loss: 0.0125 - val_mae: 0.0884\n",
      "Epoch 45/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0853 - val_loss: 0.0141 - val_mae: 0.0953\n",
      "Epoch 46/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0857 - val_loss: 0.0128 - val_mae: 0.0917\n",
      "Epoch 47/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0854 - val_loss: 0.0132 - val_mae: 0.0925\n",
      "Epoch 48/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0849 - val_loss: 0.0139 - val_mae: 0.0933\n",
      "Epoch 49/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0853 - val_loss: 0.0121 - val_mae: 0.0874\n",
      "Epoch 50/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0849 - val_loss: 0.0134 - val_mae: 0.0919\n",
      "Epoch 51/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0852 - val_loss: 0.0124 - val_mae: 0.0901\n",
      "Epoch 52/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0846 - val_loss: 0.0141 - val_mae: 0.0945\n",
      "Epoch 53/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0112 - mae: 0.0844 - val_loss: 0.0133 - val_mae: 0.0926\n",
      "Epoch 54/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0112 - mae: 0.0840 - val_loss: 0.0123 - val_mae: 0.0893\n",
      "Epoch 55/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0112 - mae: 0.0836 - val_loss: 0.0117 - val_mae: 0.0866\n",
      "Epoch 56/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0113 - mae: 0.0844 - val_loss: 0.0129 - val_mae: 0.0907\n",
      "Epoch 57/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0116 - val_mae: 0.0854\n",
      "Epoch 58/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0110 - mae: 0.0835 - val_loss: 0.0150 - val_mae: 0.0975\n",
      "Epoch 59/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0109 - mae: 0.0827 - val_loss: 0.0119 - val_mae: 0.0864\n",
      "Epoch 60/60\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0109 - mae: 0.0826 - val_loss: 0.0132 - val_mae: 0.0910\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:31:58,747] Trial 5 finished with values: [95735077509.99054, 246325.8233625702] and parameters: {'n_layers': 5, 'lr': 0.08770003499079376, 'batch_size': 16, 'epochs': 60, 'optimizer': 'SGD', 'neurons_l0': 16, 'activation_l0': 'leaky_relu', 'neurons_l1': 48, 'activation_l1': 'relu', 'neurons_l2': 32, 'activation_l2': 'leaky_relu', 'neurons_l3': 64, 'activation_l3': 'relu', 'neurons_l4': 8, 'activation_l4': 'relu'}.\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1.0210 - mae: 0.8529 - val_loss: 1.0130 - val_mae: 0.8459\n",
      "Epoch 2/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9841 - mae: 0.8390 - val_loss: 0.9863 - val_mae: 0.8358\n",
      "Epoch 3/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9612 - mae: 0.8299 - val_loss: 0.9669 - val_mae: 0.8281\n",
      "Epoch 4/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9436 - mae: 0.8226 - val_loss: 0.9511 - val_mae: 0.8217\n",
      "Epoch 5/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9289 - mae: 0.8165 - val_loss: 0.9377 - val_mae: 0.8161\n",
      "Epoch 6/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9162 - mae: 0.8110 - val_loss: 0.9259 - val_mae: 0.8111\n",
      "Epoch 7/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9047 - mae: 0.8059 - val_loss: 0.9152 - val_mae: 0.8064\n",
      "Epoch 8/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8943 - mae: 0.8013 - val_loss: 0.9053 - val_mae: 0.8020\n",
      "Epoch 9/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8846 - mae: 0.7968 - val_loss: 0.8961 - val_mae: 0.7979\n",
      "Epoch 10/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8755 - mae: 0.7926 - val_loss: 0.8875 - val_mae: 0.7940\n",
      "Epoch 11/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8670 - mae: 0.7886 - val_loss: 0.8793 - val_mae: 0.7902\n",
      "Epoch 12/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8588 - mae: 0.7847 - val_loss: 0.8715 - val_mae: 0.7866\n",
      "Epoch 13/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8510 - mae: 0.7809 - val_loss: 0.8639 - val_mae: 0.7830\n",
      "Epoch 14/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8435 - mae: 0.7772 - val_loss: 0.8566 - val_mae: 0.7795\n",
      "Epoch 15/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8363 - mae: 0.7736 - val_loss: 0.8496 - val_mae: 0.7761\n",
      "Epoch 16/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8292 - mae: 0.7701 - val_loss: 0.8427 - val_mae: 0.7727\n",
      "Epoch 17/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8224 - mae: 0.7666 - val_loss: 0.8360 - val_mae: 0.7693\n",
      "Epoch 18/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8157 - mae: 0.7632 - val_loss: 0.8294 - val_mae: 0.7661\n",
      "Epoch 19/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8091 - mae: 0.7598 - val_loss: 0.8231 - val_mae: 0.7629\n",
      "Epoch 20/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8027 - mae: 0.7565 - val_loss: 0.8169 - val_mae: 0.7597\n",
      "Epoch 21/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7964 - mae: 0.7532 - val_loss: 0.8108 - val_mae: 0.7566\n",
      "Epoch 22/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7903 - mae: 0.7499 - val_loss: 0.8048 - val_mae: 0.7535\n",
      "Epoch 23/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7843 - mae: 0.7467 - val_loss: 0.7989 - val_mae: 0.7504\n",
      "Epoch 24/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7784 - mae: 0.7435 - val_loss: 0.7931 - val_mae: 0.7473\n",
      "Epoch 25/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7726 - mae: 0.7403 - val_loss: 0.7873 - val_mae: 0.7443\n",
      "Epoch 26/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7668 - mae: 0.7372 - val_loss: 0.7817 - val_mae: 0.7412\n",
      "Epoch 27/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7612 - mae: 0.7341 - val_loss: 0.7761 - val_mae: 0.7382\n",
      "Epoch 28/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7556 - mae: 0.7310 - val_loss: 0.7706 - val_mae: 0.7352\n",
      "Epoch 29/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7501 - mae: 0.7279 - val_loss: 0.7652 - val_mae: 0.7323\n",
      "Epoch 30/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7447 - mae: 0.7248 - val_loss: 0.7598 - val_mae: 0.7293\n",
      "Epoch 31/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7393 - mae: 0.7218 - val_loss: 0.7544 - val_mae: 0.7264\n",
      "Epoch 32/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7340 - mae: 0.7188 - val_loss: 0.7492 - val_mae: 0.7235\n",
      "Epoch 33/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7287 - mae: 0.7158 - val_loss: 0.7440 - val_mae: 0.7206\n",
      "Epoch 34/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7236 - mae: 0.7128 - val_loss: 0.7389 - val_mae: 0.7177\n",
      "Epoch 35/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7184 - mae: 0.7099 - val_loss: 0.7339 - val_mae: 0.7149\n",
      "Epoch 36/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7134 - mae: 0.7069 - val_loss: 0.7289 - val_mae: 0.7120\n",
      "Epoch 37/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7084 - mae: 0.7040 - val_loss: 0.7239 - val_mae: 0.7092\n",
      "Epoch 38/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7034 - mae: 0.7011 - val_loss: 0.7190 - val_mae: 0.7064\n",
      "Epoch 39/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6986 - mae: 0.6982 - val_loss: 0.7142 - val_mae: 0.7036\n",
      "Epoch 40/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6937 - mae: 0.6954 - val_loss: 0.7094 - val_mae: 0.7008\n",
      "Epoch 41/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6890 - mae: 0.6925 - val_loss: 0.7046 - val_mae: 0.6980\n",
      "Epoch 42/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6842 - mae: 0.6896 - val_loss: 0.6999 - val_mae: 0.6953\n",
      "Epoch 43/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6795 - mae: 0.6868 - val_loss: 0.6953 - val_mae: 0.6925\n",
      "Epoch 44/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6749 - mae: 0.6840 - val_loss: 0.6907 - val_mae: 0.6898\n",
      "Epoch 45/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6702 - mae: 0.6812 - val_loss: 0.6862 - val_mae: 0.6871\n",
      "Epoch 46/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6657 - mae: 0.6784 - val_loss: 0.6818 - val_mae: 0.6844\n",
      "Epoch 47/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6612 - mae: 0.6757 - val_loss: 0.6773 - val_mae: 0.6817\n",
      "Epoch 48/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6567 - mae: 0.6729 - val_loss: 0.6730 - val_mae: 0.6790\n",
      "Epoch 49/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6523 - mae: 0.6702 - val_loss: 0.6686 - val_mae: 0.6763\n",
      "Epoch 50/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6479 - mae: 0.6675 - val_loss: 0.6643 - val_mae: 0.6736\n",
      "Epoch 51/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6436 - mae: 0.6648 - val_loss: 0.6600 - val_mae: 0.6710\n",
      "Epoch 52/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6393 - mae: 0.6621 - val_loss: 0.6557 - val_mae: 0.6683\n",
      "Epoch 53/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6350 - mae: 0.6594 - val_loss: 0.6515 - val_mae: 0.6657\n",
      "Epoch 54/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6308 - mae: 0.6568 - val_loss: 0.6473 - val_mae: 0.6631\n",
      "Epoch 55/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6266 - mae: 0.6541 - val_loss: 0.6431 - val_mae: 0.6605\n",
      "Epoch 56/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6225 - mae: 0.6515 - val_loss: 0.6390 - val_mae: 0.6579\n",
      "Epoch 57/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6184 - mae: 0.6489 - val_loss: 0.6349 - val_mae: 0.6554\n",
      "Epoch 58/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6143 - mae: 0.6463 - val_loss: 0.6308 - val_mae: 0.6529\n",
      "Epoch 59/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6103 - mae: 0.6437 - val_loss: 0.6268 - val_mae: 0.6504\n",
      "Epoch 60/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6063 - mae: 0.6412 - val_loss: 0.6229 - val_mae: 0.6479\n",
      "Epoch 61/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6023 - mae: 0.6386 - val_loss: 0.6189 - val_mae: 0.6454\n",
      "Epoch 62/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5984 - mae: 0.6361 - val_loss: 0.6150 - val_mae: 0.6430\n",
      "Epoch 63/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5945 - mae: 0.6336 - val_loss: 0.6111 - val_mae: 0.6406\n",
      "Epoch 64/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5906 - mae: 0.6311 - val_loss: 0.6073 - val_mae: 0.6381\n",
      "Epoch 65/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5868 - mae: 0.6286 - val_loss: 0.6035 - val_mae: 0.6358\n",
      "Epoch 66/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5830 - mae: 0.6262 - val_loss: 0.5997 - val_mae: 0.6334\n",
      "Epoch 67/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5793 - mae: 0.6237 - val_loss: 0.5959 - val_mae: 0.6310\n",
      "Epoch 68/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5756 - mae: 0.6213 - val_loss: 0.5922 - val_mae: 0.6286\n",
      "Epoch 69/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5719 - mae: 0.6189 - val_loss: 0.5885 - val_mae: 0.6263\n",
      "Epoch 70/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5682 - mae: 0.6165 - val_loss: 0.5848 - val_mae: 0.6240\n",
      "Epoch 71/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5646 - mae: 0.6141 - val_loss: 0.5812 - val_mae: 0.6217\n",
      "Epoch 72/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.5610 - mae: 0.6117 - val_loss: 0.5776 - val_mae: 0.6194\n",
      "Epoch 73/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.5574 - mae: 0.6094 - val_loss: 0.5740 - val_mae: 0.6171\n",
      "Epoch 74/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5539 - mae: 0.6070 - val_loss: 0.5704 - val_mae: 0.6148\n",
      "Epoch 75/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5503 - mae: 0.6047 - val_loss: 0.5669 - val_mae: 0.6126\n",
      "Epoch 76/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5469 - mae: 0.6023 - val_loss: 0.5634 - val_mae: 0.6103\n",
      "Epoch 77/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5434 - mae: 0.6000 - val_loss: 0.5599 - val_mae: 0.6080\n",
      "Epoch 78/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5400 - mae: 0.5977 - val_loss: 0.5565 - val_mae: 0.6058\n",
      "Epoch 79/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5366 - mae: 0.5954 - val_loss: 0.5530 - val_mae: 0.6036\n",
      "Epoch 80/80\n",
      "\u001b[1m225/225\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.5332 - mae: 0.5932 - val_loss: 0.5496 - val_mae: 0.6014\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:32:45,750] Trial 6 finished with values: [4415427993227.163, 1706093.4882697754] and parameters: {'n_layers': 4, 'lr': 0.0001357764594801739, 'batch_size': 32, 'epochs': 80, 'optimizer': 'Adagrad', 'neurons_l0': 48, 'activation_l0': 'leaky_relu', 'neurons_l1': 8, 'activation_l1': 'relu', 'neurons_l2': 24, 'activation_l2': 'relu', 'neurons_l3': 24, 'activation_l3': 'relu'}.\n",
      "Epoch 1/70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.3811 - mae: 0.4658 - val_loss: 0.0653 - val_mae: 0.2064\n",
      "Epoch 2/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0491 - mae: 0.1758 - val_loss: 0.0340 - val_mae: 0.1475\n",
      "Epoch 3/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0309 - mae: 0.1407 - val_loss: 0.0260 - val_mae: 0.1287\n",
      "Epoch 4/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1247 - val_loss: 0.0224 - val_mae: 0.1202\n",
      "Epoch 5/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0208 - mae: 0.1158 - val_loss: 0.0201 - val_mae: 0.1139\n",
      "Epoch 6/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0187 - mae: 0.1097 - val_loss: 0.0180 - val_mae: 0.1084\n",
      "Epoch 7/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0173 - mae: 0.1059 - val_loss: 0.0164 - val_mae: 0.1028\n",
      "Epoch 8/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0164 - mae: 0.1033 - val_loss: 0.0161 - val_mae: 0.1023\n",
      "Epoch 9/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0156 - mae: 0.1005 - val_loss: 0.0150 - val_mae: 0.0984\n",
      "Epoch 10/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0150 - mae: 0.0988 - val_loss: 0.0145 - val_mae: 0.0966\n",
      "Epoch 11/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0147 - mae: 0.0977 - val_loss: 0.0141 - val_mae: 0.0955\n",
      "Epoch 12/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0144 - mae: 0.0968 - val_loss: 0.0145 - val_mae: 0.0971\n",
      "Epoch 13/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0140 - mae: 0.0956 - val_loss: 0.0139 - val_mae: 0.0948\n",
      "Epoch 14/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0138 - mae: 0.0950 - val_loss: 0.0132 - val_mae: 0.0923\n",
      "Epoch 15/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0135 - mae: 0.0940 - val_loss: 0.0138 - val_mae: 0.0945\n",
      "Epoch 16/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0134 - mae: 0.0934 - val_loss: 0.0135 - val_mae: 0.0930\n",
      "Epoch 17/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0132 - mae: 0.0930 - val_loss: 0.0132 - val_mae: 0.0925\n",
      "Epoch 18/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0131 - mae: 0.0928 - val_loss: 0.0131 - val_mae: 0.0921\n",
      "Epoch 19/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0131 - mae: 0.0924 - val_loss: 0.0132 - val_mae: 0.0922\n",
      "Epoch 20/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0130 - mae: 0.0921 - val_loss: 0.0134 - val_mae: 0.0937\n",
      "Epoch 21/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0129 - mae: 0.0919 - val_loss: 0.0130 - val_mae: 0.0921\n",
      "Epoch 22/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0128 - mae: 0.0915 - val_loss: 0.0132 - val_mae: 0.0935\n",
      "Epoch 23/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0913 - val_loss: 0.0128 - val_mae: 0.0915\n",
      "Epoch 24/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0911 - val_loss: 0.0134 - val_mae: 0.0932\n",
      "Epoch 25/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0127 - mae: 0.0911 - val_loss: 0.0133 - val_mae: 0.0931\n",
      "Epoch 26/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0126 - mae: 0.0907 - val_loss: 0.0130 - val_mae: 0.0914\n",
      "Epoch 27/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0125 - mae: 0.0903 - val_loss: 0.0134 - val_mae: 0.0928\n",
      "Epoch 28/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0125 - mae: 0.0904 - val_loss: 0.0132 - val_mae: 0.0933\n",
      "Epoch 29/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0125 - mae: 0.0902 - val_loss: 0.0128 - val_mae: 0.0917\n",
      "Epoch 30/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0124 - mae: 0.0903 - val_loss: 0.0129 - val_mae: 0.0919\n",
      "Epoch 31/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0122 - mae: 0.0895 - val_loss: 0.0126 - val_mae: 0.0905\n",
      "Epoch 32/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0123 - mae: 0.0896 - val_loss: 0.0130 - val_mae: 0.0919\n",
      "Epoch 33/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0122 - mae: 0.0892 - val_loss: 0.0139 - val_mae: 0.0958\n",
      "Epoch 34/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0122 - mae: 0.0895 - val_loss: 0.0127 - val_mae: 0.0909\n",
      "Epoch 35/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0122 - mae: 0.0890 - val_loss: 0.0128 - val_mae: 0.0906\n",
      "Epoch 36/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0122 - mae: 0.0891 - val_loss: 0.0129 - val_mae: 0.0922\n",
      "Epoch 37/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0121 - mae: 0.0887 - val_loss: 0.0135 - val_mae: 0.0941\n",
      "Epoch 38/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0121 - mae: 0.0888 - val_loss: 0.0129 - val_mae: 0.0914\n",
      "Epoch 39/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0121 - mae: 0.0888 - val_loss: 0.0135 - val_mae: 0.0941\n",
      "Epoch 40/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119 - mae: 0.0881 - val_loss: 0.0126 - val_mae: 0.0905\n",
      "Epoch 41/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0120 - mae: 0.0883 - val_loss: 0.0126 - val_mae: 0.0908\n",
      "Epoch 42/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0120 - mae: 0.0881 - val_loss: 0.0130 - val_mae: 0.0913\n",
      "Epoch 43/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0120 - mae: 0.0883 - val_loss: 0.0127 - val_mae: 0.0902\n",
      "Epoch 44/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119 - mae: 0.0878 - val_loss: 0.0127 - val_mae: 0.0908\n",
      "Epoch 45/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0119 - mae: 0.0879 - val_loss: 0.0128 - val_mae: 0.0909\n",
      "Epoch 46/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0878 - val_loss: 0.0133 - val_mae: 0.0929\n",
      "Epoch 47/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0874 - val_loss: 0.0140 - val_mae: 0.0948\n",
      "Epoch 48/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0875 - val_loss: 0.0135 - val_mae: 0.0926\n",
      "Epoch 49/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0878 - val_loss: 0.0128 - val_mae: 0.0910\n",
      "Epoch 50/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0117 - mae: 0.0873 - val_loss: 0.0126 - val_mae: 0.0900\n",
      "Epoch 51/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0875 - val_loss: 0.0128 - val_mae: 0.0913\n",
      "Epoch 52/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0118 - mae: 0.0875 - val_loss: 0.0130 - val_mae: 0.0921\n",
      "Epoch 53/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0117 - mae: 0.0872 - val_loss: 0.0131 - val_mae: 0.0923\n",
      "Epoch 54/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0868 - val_loss: 0.0128 - val_mae: 0.0906\n",
      "Epoch 55/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0116 - mae: 0.0871 - val_loss: 0.0128 - val_mae: 0.0910\n",
      "Epoch 56/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0116 - mae: 0.0869 - val_loss: 0.0126 - val_mae: 0.0900\n",
      "Epoch 57/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0116 - mae: 0.0866 - val_loss: 0.0128 - val_mae: 0.0909\n",
      "Epoch 58/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0863 - val_loss: 0.0128 - val_mae: 0.0907\n",
      "Epoch 59/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0866 - val_loss: 0.0133 - val_mae: 0.0925\n",
      "Epoch 60/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0862 - val_loss: 0.0129 - val_mae: 0.0906\n",
      "Epoch 61/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0868 - val_loss: 0.0130 - val_mae: 0.0917\n",
      "Epoch 62/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0862 - val_loss: 0.0134 - val_mae: 0.0926\n",
      "Epoch 63/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0858 - val_loss: 0.0128 - val_mae: 0.0907\n",
      "Epoch 64/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0858 - val_loss: 0.0129 - val_mae: 0.0919\n",
      "Epoch 65/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0860 - val_loss: 0.0128 - val_mae: 0.0908\n",
      "Epoch 66/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0860 - val_loss: 0.0128 - val_mae: 0.0910\n",
      "Epoch 67/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0858 - val_loss: 0.0131 - val_mae: 0.0920\n",
      "Epoch 68/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0113 - mae: 0.0856 - val_loss: 0.0136 - val_mae: 0.0944\n",
      "Epoch 69/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0114 - mae: 0.0856 - val_loss: 0.0128 - val_mae: 0.0906\n",
      "Epoch 70/70\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0113 - mae: 0.0857 - val_loss: 0.0127 - val_mae: 0.0905\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:34:31,146] Trial 7 finished with values: [91830743470.3694, 243819.72340489502] and parameters: {'n_layers': 5, 'lr': 0.00023076090011029605, 'batch_size': 10, 'epochs': 70, 'optimizer': 'Adam', 'neurons_l0': 32, 'activation_l0': 'leaky_relu', 'neurons_l1': 8, 'activation_l1': 'relu', 'neurons_l2': 48, 'activation_l2': 'leaky_relu', 'neurons_l3': 8, 'activation_l3': 'leaky_relu', 'neurons_l4': 24, 'activation_l4': 'leaky_relu'}.\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0707 - mae: 0.1776 - val_loss: 0.0213 - val_mae: 0.1182\n",
      "Epoch 2/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0189 - mae: 0.1097 - val_loss: 0.0141 - val_mae: 0.0948\n",
      "Epoch 3/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0159 - mae: 0.0998 - val_loss: 0.0139 - val_mae: 0.0909\n",
      "Epoch 4/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0143 - mae: 0.0931 - val_loss: 0.0100 - val_mae: 0.0748\n",
      "Epoch 5/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0115 - mae: 0.0793 - val_loss: 0.0122 - val_mae: 0.0816\n",
      "Epoch 6/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0103 - mae: 0.0723 - val_loss: 0.0122 - val_mae: 0.0837\n",
      "Epoch 7/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0098 - mae: 0.0686 - val_loss: 0.0084 - val_mae: 0.0641\n",
      "Epoch 8/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0094 - mae: 0.0661 - val_loss: 0.0077 - val_mae: 0.0572\n",
      "Epoch 9/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0092 - mae: 0.0644 - val_loss: 0.0086 - val_mae: 0.0660\n",
      "Epoch 10/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0090 - mae: 0.0631 - val_loss: 0.0117 - val_mae: 0.0804\n",
      "Epoch 11/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0089 - mae: 0.0620 - val_loss: 0.0107 - val_mae: 0.0771\n",
      "Epoch 12/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0617 - val_loss: 0.0076 - val_mae: 0.0574\n",
      "Epoch 13/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0609 - val_loss: 0.0079 - val_mae: 0.0588\n",
      "Epoch 14/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0087 - mae: 0.0605 - val_loss: 0.0100 - val_mae: 0.0689\n",
      "Epoch 15/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 - mae: 0.0597 - val_loss: 0.0074 - val_mae: 0.0535\n",
      "Epoch 16/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0085 - mae: 0.0595 - val_loss: 0.0068 - val_mae: 0.0469\n",
      "Epoch 17/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0084 - mae: 0.0586 - val_loss: 0.0108 - val_mae: 0.0731\n",
      "Epoch 18/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0084 - mae: 0.0585 - val_loss: 0.0077 - val_mae: 0.0557\n",
      "Epoch 19/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0583 - val_loss: 0.0078 - val_mae: 0.0543\n",
      "Epoch 20/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.0082 - mae: 0.0578 - val_loss: 0.0072 - val_mae: 0.0505\n",
      "Epoch 21/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0083 - mae: 0.0573 - val_loss: 0.0072 - val_mae: 0.0504\n",
      "Epoch 22/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0082 - mae: 0.0566 - val_loss: 0.0085 - val_mae: 0.0638\n",
      "Epoch 23/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0566 - val_loss: 0.0067 - val_mae: 0.0487\n",
      "Epoch 24/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0564 - val_loss: 0.0066 - val_mae: 0.0486\n",
      "Epoch 25/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0081 - mae: 0.0562 - val_loss: 0.0086 - val_mae: 0.0640\n",
      "Epoch 26/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0557 - val_loss: 0.0088 - val_mae: 0.0675\n",
      "Epoch 27/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0550 - val_loss: 0.0087 - val_mae: 0.0630\n",
      "Epoch 28/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0553 - val_loss: 0.0076 - val_mae: 0.0518\n",
      "Epoch 29/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0545 - val_loss: 0.0068 - val_mae: 0.0483\n",
      "Epoch 30/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0543 - val_loss: 0.0107 - val_mae: 0.0735\n",
      "Epoch 31/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0541 - val_loss: 0.0071 - val_mae: 0.0496\n",
      "Epoch 32/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0525 - val_loss: 0.0064 - val_mae: 0.0453\n",
      "Epoch 33/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0512 - val_loss: 0.0068 - val_mae: 0.0520\n",
      "Epoch 34/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0500 - val_loss: 0.0068 - val_mae: 0.0538\n",
      "Epoch 35/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0059 - mae: 0.0475 - val_loss: 0.0067 - val_mae: 0.0572\n",
      "Epoch 36/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0049 - mae: 0.0447 - val_loss: 0.0048 - val_mae: 0.0479\n",
      "Epoch 37/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0038 - mae: 0.0406 - val_loss: 0.0030 - val_mae: 0.0380\n",
      "Epoch 38/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0029 - mae: 0.0375 - val_loss: 0.0023 - val_mae: 0.0339\n",
      "Epoch 39/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0022 - mae: 0.0338 - val_loss: 0.0025 - val_mae: 0.0385\n",
      "Epoch 40/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0017 - mae: 0.0312 - val_loss: 0.0012 - val_mae: 0.0258\n",
      "Epoch 41/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0015 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 42/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0014 - mae: 0.0281 - val_loss: 4.7563e-04 - val_mae: 0.0157\n",
      "Epoch 43/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0268 - val_loss: 9.6805e-04 - val_mae: 0.0240\n",
      "Epoch 44/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0012 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 45/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0257 - val_loss: 0.0015 - val_mae: 0.0330\n",
      "Epoch 46/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0251 - val_loss: 4.1169e-04 - val_mae: 0.0157\n",
      "Epoch 47/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0011 - mae: 0.0250 - val_loss: 2.5818e-04 - val_mae: 0.0124\n",
      "Epoch 48/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0010 - mae: 0.0238 - val_loss: 6.5784e-04 - val_mae: 0.0208\n",
      "Epoch 49/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.9162e-04 - mae: 0.0237 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 50/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.6006e-04 - mae: 0.0234 - val_loss: 3.6271e-04 - val_mae: 0.0152\n",
      "Epoch 51/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.6027e-04 - mae: 0.0234 - val_loss: 4.6704e-04 - val_mae: 0.0170\n",
      "Epoch 52/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 9.1594e-04 - mae: 0.0227 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 53/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.7692e-04 - mae: 0.0223 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 54/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.6785e-04 - mae: 0.0226 - val_loss: 3.5613e-04 - val_mae: 0.0148\n",
      "Epoch 55/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.3304e-04 - mae: 0.0219 - val_loss: 0.0023 - val_mae: 0.0398\n",
      "Epoch 56/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 8.3102e-04 - mae: 0.0216 - val_loss: 2.3328e-04 - val_mae: 0.0120\n",
      "Epoch 57/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 7.6400e-04 - mae: 0.0207 - val_loss: 3.7767e-04 - val_mae: 0.0153\n",
      "Epoch 58/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.5087e-04 - mae: 0.0206 - val_loss: 4.6761e-04 - val_mae: 0.0160\n",
      "Epoch 59/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3515e-04 - mae: 0.0203 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 60/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.3453e-04 - mae: 0.0204 - val_loss: 0.0015 - val_mae: 0.0342\n",
      "Epoch 61/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.2631e-04 - mae: 0.0204 - val_loss: 2.0057e-04 - val_mae: 0.0112\n",
      "Epoch 62/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.1460e-04 - mae: 0.0201 - val_loss: 2.9576e-04 - val_mae: 0.0135\n",
      "Epoch 63/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.9723e-04 - mae: 0.0194 - val_loss: 2.2137e-04 - val_mae: 0.0117\n",
      "Epoch 64/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 7.0468e-04 - mae: 0.0200 - val_loss: 2.8726e-04 - val_mae: 0.0125\n",
      "Epoch 65/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.9383e-04 - mae: 0.0196 - val_loss: 8.1948e-04 - val_mae: 0.0228\n",
      "Epoch 66/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6532e-04 - mae: 0.0194 - val_loss: 4.4932e-04 - val_mae: 0.0166\n",
      "Epoch 67/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6090e-04 - mae: 0.0193 - val_loss: 5.8330e-04 - val_mae: 0.0189\n",
      "Epoch 68/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.6002e-04 - mae: 0.0192 - val_loss: 7.7975e-04 - val_mae: 0.0205\n",
      "Epoch 69/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.4759e-04 - mae: 0.0189 - val_loss: 2.9053e-04 - val_mae: 0.0138\n",
      "Epoch 70/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.3667e-04 - mae: 0.0189 - val_loss: 6.2828e-04 - val_mae: 0.0175\n",
      "Epoch 71/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.2995e-04 - mae: 0.0184 - val_loss: 4.0057e-04 - val_mae: 0.0161\n",
      "Epoch 72/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 6.1969e-04 - mae: 0.0185 - val_loss: 2.6455e-04 - val_mae: 0.0125\n",
      "Epoch 73/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.1484e-04 - mae: 0.0186 - val_loss: 0.0012 - val_mae: 0.0295\n",
      "Epoch 74/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.0948e-04 - mae: 0.0184 - val_loss: 4.7818e-04 - val_mae: 0.0174\n",
      "Epoch 75/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 6.1053e-04 - mae: 0.0181 - val_loss: 5.8835e-04 - val_mae: 0.0185\n",
      "Epoch 76/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.8751e-04 - mae: 0.0183 - val_loss: 2.5876e-04 - val_mae: 0.0128\n",
      "Epoch 77/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.9598e-04 - mae: 0.0178 - val_loss: 3.1165e-04 - val_mae: 0.0134\n",
      "Epoch 78/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.9134e-04 - mae: 0.0178 - val_loss: 1.9798e-04 - val_mae: 0.0112\n",
      "Epoch 79/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 5.7749e-04 - mae: 0.0178 - val_loss: 3.7658e-04 - val_mae: 0.0149\n",
      "Epoch 80/80\n",
      "\u001b[1m720/720\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 5.9200e-04 - mae: 0.0179 - val_loss: 3.0026e-04 - val_mae: 0.0135\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:36:11,540] Trial 8 finished with values: [2442509284.592162, 38281.055134376904] and parameters: {'n_layers': 3, 'lr': 0.003015909948949744, 'batch_size': 10, 'epochs': 80, 'optimizer': 'RMSprop', 'neurons_l0': 16, 'activation_l0': 'leaky_relu', 'neurons_l1': 8, 'activation_l1': 'relu', 'neurons_l2': 56, 'activation_l2': 'relu'}.\n",
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
      "C:\\Users\\kiril\\AppData\\Local\\Temp\\ipykernel_2432\\3229763493.py:11: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "Positional arguments ['self', 'name', 'low', 'high', 'step', 'log'] in suggest_int() have been deprecated since v3.5.0. They will be replaced with the corresponding keyword arguments in v5.0.0, so please use the keyword specification instead. See https://github.com/optuna/optuna/releases/tag/v3.5.0 for details.\n",
      "  epochs = trial.suggest_int('epochs', 50, 100,10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 1.0932 - mae: 0.8906 - val_loss: 1.0891 - val_mae: 0.8858\n",
      "Epoch 2/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0701 - mae: 0.8823 - val_loss: 1.0715 - val_mae: 0.8795\n",
      "Epoch 3/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0548 - mae: 0.8766 - val_loss: 1.0581 - val_mae: 0.8745\n",
      "Epoch 4/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0425 - mae: 0.8719 - val_loss: 1.0469 - val_mae: 0.8703\n",
      "Epoch 5/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0321 - mae: 0.8680 - val_loss: 1.0372 - val_mae: 0.8666\n",
      "Epoch 6/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0229 - mae: 0.8644 - val_loss: 1.0285 - val_mae: 0.8633\n",
      "Epoch 7/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0146 - mae: 0.8612 - val_loss: 1.0206 - val_mae: 0.8602\n",
      "Epoch 8/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0071 - mae: 0.8583 - val_loss: 1.0134 - val_mae: 0.8574\n",
      "Epoch 9/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.0001 - mae: 0.8556 - val_loss: 1.0066 - val_mae: 0.8547\n",
      "Epoch 10/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9936 - mae: 0.8530 - val_loss: 1.0004 - val_mae: 0.8522\n",
      "Epoch 11/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9875 - mae: 0.8506 - val_loss: 0.9945 - val_mae: 0.8498\n",
      "Epoch 12/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9818 - mae: 0.8483 - val_loss: 0.9889 - val_mae: 0.8476\n",
      "Epoch 13/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9764 - mae: 0.8461 - val_loss: 0.9835 - val_mae: 0.8454\n",
      "Epoch 14/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9712 - mae: 0.8440 - val_loss: 0.9785 - val_mae: 0.8433\n",
      "Epoch 15/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9663 - mae: 0.8420 - val_loss: 0.9736 - val_mae: 0.8413\n",
      "Epoch 16/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9616 - mae: 0.8400 - val_loss: 0.9689 - val_mae: 0.8394\n",
      "Epoch 17/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9570 - mae: 0.8381 - val_loss: 0.9644 - val_mae: 0.8375\n",
      "Epoch 18/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9526 - mae: 0.8363 - val_loss: 0.9600 - val_mae: 0.8357\n",
      "Epoch 19/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9484 - mae: 0.8345 - val_loss: 0.9558 - val_mae: 0.8339\n",
      "Epoch 20/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9443 - mae: 0.8328 - val_loss: 0.9517 - val_mae: 0.8321\n",
      "Epoch 21/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9403 - mae: 0.8311 - val_loss: 0.9478 - val_mae: 0.8304\n",
      "Epoch 22/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9365 - mae: 0.8294 - val_loss: 0.9439 - val_mae: 0.8287\n",
      "Epoch 23/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9327 - mae: 0.8278 - val_loss: 0.9402 - val_mae: 0.8271\n",
      "Epoch 24/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9291 - mae: 0.8263 - val_loss: 0.9366 - val_mae: 0.8255\n",
      "Epoch 25/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9255 - mae: 0.8247 - val_loss: 0.9330 - val_mae: 0.8239\n",
      "Epoch 26/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9220 - mae: 0.8232 - val_loss: 0.9296 - val_mae: 0.8224\n",
      "Epoch 27/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9186 - mae: 0.8217 - val_loss: 0.9262 - val_mae: 0.8209\n",
      "Epoch 28/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9153 - mae: 0.8203 - val_loss: 0.9228 - val_mae: 0.8194\n",
      "Epoch 29/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9121 - mae: 0.8189 - val_loss: 0.9196 - val_mae: 0.8180\n",
      "Epoch 30/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9089 - mae: 0.8175 - val_loss: 0.9164 - val_mae: 0.8165\n",
      "Epoch 31/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9058 - mae: 0.8161 - val_loss: 0.9133 - val_mae: 0.8151\n",
      "Epoch 32/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.9027 - mae: 0.8147 - val_loss: 0.9102 - val_mae: 0.8137\n",
      "Epoch 33/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8997 - mae: 0.8134 - val_loss: 0.9072 - val_mae: 0.8123\n",
      "Epoch 34/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8967 - mae: 0.8121 - val_loss: 0.9042 - val_mae: 0.8109\n",
      "Epoch 35/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8938 - mae: 0.8108 - val_loss: 0.9013 - val_mae: 0.8096\n",
      "Epoch 36/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8910 - mae: 0.8095 - val_loss: 0.8985 - val_mae: 0.8083\n",
      "Epoch 37/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8881 - mae: 0.8082 - val_loss: 0.8957 - val_mae: 0.8070\n",
      "Epoch 38/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8854 - mae: 0.8070 - val_loss: 0.8929 - val_mae: 0.8057\n",
      "Epoch 39/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8827 - mae: 0.8057 - val_loss: 0.8902 - val_mae: 0.8044\n",
      "Epoch 40/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8800 - mae: 0.8045 - val_loss: 0.8876 - val_mae: 0.8031\n",
      "Epoch 41/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8773 - mae: 0.8033 - val_loss: 0.8849 - val_mae: 0.8018\n",
      "Epoch 42/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8747 - mae: 0.8021 - val_loss: 0.8823 - val_mae: 0.8006\n",
      "Epoch 43/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8721 - mae: 0.8009 - val_loss: 0.8798 - val_mae: 0.7994\n",
      "Epoch 44/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8696 - mae: 0.7998 - val_loss: 0.8772 - val_mae: 0.7982\n",
      "Epoch 45/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8671 - mae: 0.7986 - val_loss: 0.8747 - val_mae: 0.7970\n",
      "Epoch 46/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8646 - mae: 0.7975 - val_loss: 0.8723 - val_mae: 0.7958\n",
      "Epoch 47/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8622 - mae: 0.7963 - val_loss: 0.8698 - val_mae: 0.7946\n",
      "Epoch 48/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8598 - mae: 0.7952 - val_loss: 0.8674 - val_mae: 0.7934\n",
      "Epoch 49/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8574 - mae: 0.7941 - val_loss: 0.8650 - val_mae: 0.7922\n",
      "Epoch 50/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8551 - mae: 0.7930 - val_loss: 0.8627 - val_mae: 0.7911\n",
      "Epoch 51/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8527 - mae: 0.7919 - val_loss: 0.8604 - val_mae: 0.7900\n",
      "Epoch 52/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8504 - mae: 0.7908 - val_loss: 0.8581 - val_mae: 0.7888\n",
      "Epoch 53/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8482 - mae: 0.7897 - val_loss: 0.8558 - val_mae: 0.7877\n",
      "Epoch 54/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8459 - mae: 0.7886 - val_loss: 0.8535 - val_mae: 0.7866\n",
      "Epoch 55/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8437 - mae: 0.7876 - val_loss: 0.8513 - val_mae: 0.7855\n",
      "Epoch 56/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8415 - mae: 0.7865 - val_loss: 0.8491 - val_mae: 0.7844\n",
      "Epoch 57/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8393 - mae: 0.7855 - val_loss: 0.8469 - val_mae: 0.7833\n",
      "Epoch 58/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8371 - mae: 0.7845 - val_loss: 0.8447 - val_mae: 0.7822\n",
      "Epoch 59/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8350 - mae: 0.7834 - val_loss: 0.8426 - val_mae: 0.7811\n",
      "Epoch 60/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8329 - mae: 0.7824 - val_loss: 0.8405 - val_mae: 0.7801\n",
      "Epoch 61/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8308 - mae: 0.7814 - val_loss: 0.8384 - val_mae: 0.7790\n",
      "Epoch 62/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8287 - mae: 0.7804 - val_loss: 0.8363 - val_mae: 0.7780\n",
      "Epoch 63/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8266 - mae: 0.7794 - val_loss: 0.8342 - val_mae: 0.7769\n",
      "Epoch 64/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8246 - mae: 0.7784 - val_loss: 0.8321 - val_mae: 0.7759\n",
      "Epoch 65/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8226 - mae: 0.7774 - val_loss: 0.8301 - val_mae: 0.7749\n",
      "Epoch 66/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8206 - mae: 0.7765 - val_loss: 0.8281 - val_mae: 0.7739\n",
      "Epoch 67/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8186 - mae: 0.7755 - val_loss: 0.8261 - val_mae: 0.7728\n",
      "Epoch 68/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8166 - mae: 0.7745 - val_loss: 0.8241 - val_mae: 0.7718\n",
      "Epoch 69/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8147 - mae: 0.7735 - val_loss: 0.8221 - val_mae: 0.7708\n",
      "Epoch 70/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8127 - mae: 0.7726 - val_loss: 0.8202 - val_mae: 0.7699\n",
      "Epoch 71/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8108 - mae: 0.7716 - val_loss: 0.8183 - val_mae: 0.7689\n",
      "Epoch 72/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8089 - mae: 0.7707 - val_loss: 0.8163 - val_mae: 0.7679\n",
      "Epoch 73/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8070 - mae: 0.7698 - val_loss: 0.8144 - val_mae: 0.7669\n",
      "Epoch 74/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8051 - mae: 0.7688 - val_loss: 0.8125 - val_mae: 0.7659\n",
      "Epoch 75/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8032 - mae: 0.7679 - val_loss: 0.8106 - val_mae: 0.7650\n",
      "Epoch 76/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.8014 - mae: 0.7670 - val_loss: 0.8087 - val_mae: 0.7640\n",
      "Epoch 77/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7995 - mae: 0.7661 - val_loss: 0.8069 - val_mae: 0.7630\n",
      "Epoch 78/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7977 - mae: 0.7651 - val_loss: 0.8050 - val_mae: 0.7621\n",
      "Epoch 79/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7959 - mae: 0.7642 - val_loss: 0.8032 - val_mae: 0.7611\n",
      "Epoch 80/80\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7940 - mae: 0.7633 - val_loss: 0.8013 - val_mae: 0.7602\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "[I 2025-10-24 17:37:24,218] Trial 9 finished with values: [6572972194388.151, 2194216.5156937498] and parameters: {'n_layers': 5, 'lr': 2.5169669381625926e-05, 'batch_size': 16, 'epochs': 80, 'optimizer': 'Adagrad', 'neurons_l0': 40, 'activation_l0': 'leaky_relu', 'neurons_l1': 16, 'activation_l1': 'leaky_relu', 'neurons_l2': 48, 'activation_l2': 'relu', 'neurons_l3': 64, 'activation_l3': 'leaky_relu', 'neurons_l4': 40, 'activation_l4': 'relu'}.\n",
      " MAE (train, test): [2442509284.592162, 38281.055134376904]\n",
      " MSE (train, test): 2442509284.592162, 2706714880.2146716\n",
      ": {'n_layers': 3, 'lr': 0.003015909948949744, 'batch_size': 10, 'epochs': 80, 'optimizer': 'RMSprop', 'neurons_l0': 16, 'activation_l0': 'leaky_relu', 'neurons_l1': 8, 'activation_l1': 'relu', 'neurons_l2': 56, 'activation_l2': 'relu'}\n",
      "[neptune] [info   ] Shutting down background jobs, please wait a moment...\n",
      "[neptune] [info   ] Done!\n",
      "[neptune] [info   ] All 0 operations synced, thanks for waiting!\n",
      "[neptune] [info   ] Explore the metadata in the Neptune app: https://app.neptune.ai/kulikovka/paris-boston-test/e/PAR-73/metadata\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "run = neptune.init_run(\n",
    "    project=\"kulikovka/paris-boston-test\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJiNjZjNWE3OS1jMzRlLTQyZjAtYmFiNi04ZGU1ZjY0MDAxNzgifQ==\"\n",
    ")\n",
    "\n",
    "\n",
    "def objective_optuna_paris(trial):\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 2, 6)\n",
    "    lr = trial.suggest_loguniform('lr', 1e-5, 1e-1)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [10,16, 32, 64])\n",
    "    epochs = trial.suggest_int('epochs', 50, 100,10)\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['Adam', 'SGD', 'RMSprop', 'Adagrad'])\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(15,)))\n",
    "    for i in range(n_layers):\n",
    "        neurons = trial.suggest_int(f\"neurons_l{i}\", 8, 64, step=8)\n",
    "        activation = trial.suggest_categorical(f\"activation_l{i}\", [\"relu\", \"leaky_relu\"])\n",
    "        model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    if optimizer == \"Adam\":\n",
    "        opt = Adam(learning_rate=lr)\n",
    "    elif optimizer == \"SGD\":\n",
    "        opt = SGD(learning_rate=lr)\n",
    "    elif optimizer == \"RMSprop\":\n",
    "        opt = RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        opt = Adagrad(learning_rate=lr)\n",
    "\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mae'])\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train_pca_paris, y_train_paris,\n",
    "        epochs=epochs, batch_size=batch_size,\n",
    "        verbose=1, validation_split=0.1\n",
    "    )\n",
    "\n",
    "    y_train_pred = y_scaler.inverse_transform(model.predict(X_train_pca_paris))\n",
    "    y_test_pred = y_scaler.inverse_transform(model.predict(X_test_pca_paris))\n",
    "    y_train_real = y_scaler.inverse_transform(y_train_paris)\n",
    "    y_test_real = y_scaler.inverse_transform(y_test_paris)\n",
    "\n",
    "    train_mae = mean_absolute_error(y_train_real, y_train_pred)\n",
    "    test_mae = mean_absolute_error(y_test_real, y_test_pred)\n",
    "    train_mse = mean_squared_error(y_train_real, y_train_pred)\n",
    "    test_mse = mean_squared_error(y_test_real, y_test_pred)\n",
    "\n",
    "    trial.set_user_attr(\"train_mae\", train_mae)\n",
    "    trial.set_user_attr(\"test_mae\", test_mae)\n",
    "    trial.set_user_attr(\"train_mse\", train_mse)\n",
    "    trial.set_user_attr(\"test_mse\", test_mse)\n",
    "\n",
    "    run[\"optuna/train_mae\"].log(train_mae)\n",
    "    run[\"optuna/test_mae\"].log(test_mae)\n",
    "    run[\"optuna/train_mse\"].log(train_mse)\n",
    "    run[\"optuna/test_mse\"].log(test_mse)\n",
    "\n",
    "    return train_mse, train_mae  \n",
    "\n",
    "study_multi = optuna.create_study(directions=['minimize','minimize'])\n",
    "study_multi.optimize(objective_optuna_paris, n_trials=10, show_progress_bar=True)\n",
    "\n",
    "for trial in study_multi.best_trials:\n",
    "    print(f\" MAE (train, test): {trial.values}\")\n",
    "    print(f\" MSE (train, test): {trial.user_attrs['train_mse']}, {trial.user_attrs['test_mse']}\")\n",
    "    print(f\": {trial.params}\")\n",
    "\n",
    "run.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d25c43f",
   "metadata": {},
   "source": [
    "#  \n",
    "## PCA\n",
    "-     Boston,  4 ,  \n",
    "-     Paris,   , PCA      .\n",
    "- -  MAE    2.8k vs 15k\n",
    "##   \n",
    "- Optuna  Hyperopt   +-    **Boston**\n",
    "-  Optuna   Hyperopt      ,      \n",
    "-   **Paris** Optuna     Hyperopt.\n",
    "-           ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2971e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62f9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155b47b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLops_main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
