{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a35136e",
   "metadata": {},
   "source": [
    "# Что такое CNN?\n",
    "- ***Свёрточные нейронные сети*** (CNN) — это специализированный класс искусственных нейронных сетей, разработанный для задач, где важна *пространственная структура данных*, например, обработка изображений или видео. Впервые их идея была предложена Яном Лекуном в 1988 году, а широкую известность они получили после победы **AlexNet** в конкурсе ImageNet в 2012 году. CNN вдохновлены биологией: в зрительной коре мозга есть нейроны, реагирующие на локальные области, и эта концепция легла в основу их архитектуры.\n",
    "\n",
    "- Сегодня CNN применяются повсеместно: от распознавания лиц в смартфонах до анализа медицинских снимков и управления беспилотными автомобилями. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3482120",
   "metadata": {},
   "source": [
    "# Почему CNN эффективны?\n",
    "\n",
    "\n",
    "-  **Почему обычные сети не подходят?**\n",
    "     - Полносвязные нейронные сети, где каждый нейрон соединён со всеми нейронами предыдущего слоя, плохо работают с изображениями. Для картинки 100x100 пикселей (10 000 входов) и скрытого слоя с 100 нейронами потребуется 1 миллион весов. Это не только медленно, но и не учитывает, что соседние пиксели связаны между собой (например, образуют края или текстуры). CNN решают эту проблему с помощью локальных операций.\n",
    "\n",
    "- **Операция свёртки**\n",
    "     - Свёртка — это процесс, где небольшое ядро (фильтр) скользит по изображению и вычисляет новые значения, выделяя локальные признаки.\n",
    "\n",
    "\n",
    "- **Преимущество сверточных нейронных сетей** заключается в их способности *автоматически изучать признаки на основе необработанных данных изображений*. В старых методах машинного обучения исследователям приходилось вручную определять, какие признаки важны. Сверточные нейронные сети устраняют это ограничение, позволяя модели ***самостоятельно выявлять закономерности***.\n",
    "\n",
    "- **Вот почему CNN особенно эффективны**:\n",
    "\n",
    "    - ***Инвариантность перевода***: Кошка остается кошкой, независимо от того, где она находится — в верхнем левом или нижнем правом углу изображения.\n",
    "    - ***Эффективность параметра***: Вместо того чтобы изучать отдельные веса для каждого пикселя, сверточные нейронные сети повторно используют фильтры, что делает их вычислительно эффективными.\n",
    "    - **Иерархическое обучение признакам**: Нижние слои фиксируют базовые формы, в то время как более глубокие слои фиксируют концепции высокого уровня.\n",
    "Такое сочетание позволяет сверточным нейронным сетям достигать почти человеческой или даже сверхчеловеческой производительности при решении задач классификации изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cef269a",
   "metadata": {},
   "source": [
    "# Математика свертки\n",
    "Для изображения $I$ и ядра $K$ размером $m \\times n$:\n",
    "\n",
    "$(I * K)$ $(x, y)$ = **$\\sum_{i=0}^{m-1} $** **$\\sum_{j=0}^{n-1}$** $I(x+i, y+j) \\cdot K(i, j)$ \n",
    "\n",
    "Пример:\n",
    "\n",
    "$$\n",
    "\\text{Изображение } I \\text{ (5×5):} \\quad\n",
    "I = \n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 & 4 & 5 \\\\\n",
    "2 & 3 & 4 & 5 & 6 \\\\\n",
    "3 & 4 & 5 & 6 & 7 \\\\\n",
    "4 & 5 & 6 & 7 & 8 \\\\\n",
    "5 & 6 & 7 & 8 & 9 \\\\\n",
    "\\end{bmatrix}\n",
    "\\quad\n",
    "\\text{Ядро } K \\text{ (3×3, вертикальные края):} \\quad\n",
    "K = \n",
    "\\begin{bmatrix}\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "-1 & 0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "$$\\text{Свёртка  в   позиции } (1,1): (-1) \\cdot 1 + 0 \\cdot 2 + 1 \\cdot 3 + (-1) \\cdot 2 + 0 \\cdot 3 + 1 \\cdot 4 + (-1) \\cdot 3 + 0 \\cdot 4 + 1 \\cdot 5 = -1 + 3 - 2 + 4 - 3 + 5 = 6$$\n",
    "**Результат** — карта признаков, где яркие области показывают вертикальные края.\n",
    "\n",
    "##### **Параметры**\n",
    "**Размер ядра**: обычно 3x3 или 5x5.\n",
    "\n",
    "**Шаг (stride)**: расстояние сдвига ядра (1 или 2).\n",
    "\n",
    "**Дополнение (padding)**: добавление значений по краям (same padding — сохраняет размер, valid — уменьшает).\n",
    "\n",
    "\n",
    "Перейдя по этой ссылке ( https://setosa.io/ev/image-kernels/) можно отлично увидеть как работает свёртка."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c37e607",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c95304cf",
   "metadata": {},
   "source": [
    "# Dropout и Batch Normalization\n",
    "***Dropout*** предполагает случайный кик нейронов из процесса обучения, обеспечивает, чтобы нейронная сеть не стала слишком зависимой от любого одного узла. Сравнить это можно с dropout в спортивных играх. Там это стратегия, которая заставляет каждого игрока команды играть лучше, а не полагаться только на одного звездного товарища.\n",
    "\n",
    "***Batch Normalization*** в свою очередь улучшает производительность и стабильность нейронных сетей путем нормализации входных данных каждого слоя.\n",
    "\n",
    "### **Dropout**\n",
    "\n",
    "- Основная идея Dropout заключается в **случайном «выключении»** (то есть временном исключении из обучения) определенного процента нейронов в сети на каждом шаге обучения. Это означает, что во время каждого прохода обучения (или каждой эпохи) случайно выбранный набор нейронов игнорируется. Это помогает предотвратить ***чрезмерную зависимость модели от конкретных путей и узлов в сети***, что может привести к **переобучению**.\n",
    "\n",
    "- *Сначала выбирается вероятность **p**, с которой каждый нейрон будет исключаться*. Обычно pнаходится в диапазоне от **0.2 до 0.5**.\n",
    "\n",
    "- Для каждого слоя, где применяется Dropout, генерируется **случайная маска**. Эта маска имеет *ту же размерность, что и слой*, и каждый её элемент является бинарным **(0 или 1)**, где **1** соответствует активации нейрона, а **0** — его отключению. Эта маска генерируется заново для каждого прохода обучения и для каждого обучающего примера. Активации нейронов умножаются на эту маску, эффективно «выключая» некоторые нейроны.\n",
    "\n",
    "- В процессе обратного распространения ошибки, *градиенты рассчитываются только для **активных нейронов***. Нейроны, которые были временно «выключены», не получают обновлений весов.\n",
    "\n",
    "- Во время тестирования или инференции Dropout отключается. Однако, активации нейронов масштабируются на коэффициент, равный вероятности p, чтобы компенсировать большее количество активных нейронов по сравнению с обучением. Это масштабирование помогает сохранить общую сумму активаций на похожем уровне между обучением и тестированием.\n",
    "\n",
    "- Математически, *Dropout можно интерпретировать как ансамблевый метод*. Каждый проход обучения использует случайно отобранную «тонкую» сеть, что похоже на обучение множества разных моделей и усреднение их прогнозов.\n",
    "\n",
    "### **Подходы к определению оптимальной степени Dropout**\n",
    "\n",
    " — Положение слоев **DropВ CNN Dropout** часто помещают после сверточных и пулинговых слоев. Это помогает снизить переадаптацию к тренировочным данным, сохраняя при этом пространственные особенности изображений.\n",
    "\n",
    " — Меньшие значения: Для CNN значения Dropout обычно ниже, чем для MLP(многослойный перцептрон), так как сверточные слои менее склонны к переобучению. Общие значения находятся в **диапазоне от 0.1 до 0.3**.\n",
    "\n",
    "### **Batch Normalization**\n",
    " \n",
    " - **Batch Normalization (BN)** предназначен для улучшения скорости, производительности и стабильности обучения нейронных сетей.\n",
    "\n",
    " - В основе Batch Normalization лежит решение проблемы «внутреннего ковариационного сдвига» (Internal Covariate Shift). Этот термин описывает явление, при котором распределение входных данных каждого слоя нейронной сети меняется в процессе обучения, из-за чего сети становится сложнее обучать. Это происходит из-за того, что параметры предыдущих слоев изменяются во время обучения, влияя на данные текущего слоя.\n",
    "\n",
    " - **Batch Normalization решает эту проблему**, нормализуя выход каждого слоя. Нормализация заключается в преобразовании входных данных каждого слоя таким образом, чтобы **среднее значение было приближено к нулю**, а **стандартное отклонение — к единице**. Это делает сеть менее чувствительной к масштабу входных данных и улучшает общую стабильность процесса обучения.\n",
    "\n",
    "К примеру, для мини-пакета алгоритм будет следующим:\n",
    "\n",
    "где **$m$** — размер мини-пакета, BN трансформирует каждый вход **$x_i$** следующим образом:\n",
    "1. Вычисление среднего:  \n",
    "$\\mu_B = \\frac{1}{m} \\sum_{i=1}^{m} x_i$\n",
    "\n",
    "2. Вычисление дисперсии:  \n",
    "$\\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^{m} (x_i - \\mu_B)^2$\n",
    "\n",
    "3. Нормализация:  \n",
    "$\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}$\n",
    "где $\\epsilon$ — маленькое число для избежания деления на ноль.\n",
    "\n",
    "4. Масштабирование и сдвиг:  \n",
    "$y_i = \\gamma \\hat{x}_i + \\beta$  \n",
    "где $\\gamma$ и $\\beta$ — параметры, которые сеть обучается настраивать.\n",
    "\n",
    "\n",
    "- В CNN, BN обычно размещается сразу после сверточных слоев (Convolutional Layers) и перед активационной функцией, такой как ReLU. Порядок обычно следующий: **Свертка → Batch Normalization → Активация**.\n",
    "\n",
    "- В сверточных слоях BN применяется отдельно к каждому каналу выходных данных свертки. Это означает, что для каждого фильтра сверточного слоя вычисляется собственное среднее и дисперсия.\n",
    "\n",
    "- При этом сохраняется пространственная структура выходных данных, т.е. нормализация не влияет на пространственное расположение признаков.\n",
    "\n",
    "- В некоторых случаях BN может служить регуляризатором, уменьшая необходимость в Dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e875b4a9",
   "metadata": {},
   "source": [
    "# **VGG**\n",
    "\n",
    "### **Что такое VGG ?**\n",
    "\n",
    "- VGG (*Visual Geometry Group*, Оксфорд) — семейство простых, но глубоких сверточных сетей, предложенное в 2014 (Simonyan & Zisserman). **Главное отличие — последовательность маленьких 3×3 свёрток вместо больших ядер.** Это показало, что глубина сети (количество слоёв) важнее сложных структур: VGG простая, предсказуемая, и хорошо работает как «фиче-экстрактор».\n",
    "\n",
    "**Основные варианты:**\n",
    " - VGG16 — 16 слоёв, содержащих веса (13 conv + 3 FC).\n",
    " - VGG19 — 19 слоёв с весами (16 conv + 3 FC).\n",
    "\n",
    "Обычно используются входы 224×224×3 (как в ImageNet). Сеть обучали на ImageNet (≈1.2M изображений, 1000 классов).\n",
    "\n",
    "### **Архитектура**\n",
    "<img src=\"./CNN/vgg.jpg\" width=\"1000\" height=\"400\" align=\"center\">\n",
    "\n",
    "**Вход:** 224×224×3  \n",
    "→ **Две свертки 3×3×64** → MaxPool 2×2 → 112×112×64  \n",
    "→ **Две свертки 3×3×128** → MaxPool 2×2 → 56×56×128  \n",
    "→ **Три свертки 3×3×256** → MaxPool 2×2 → 28×28×256  \n",
    "→ **Три свертки 3×3×512** → MaxPool 2×2 → 14×14×512  \n",
    "→ **Три свертки 3×3×512** → MaxPool 2×2 → 7×7×512  \n",
    "→ **Flatten** → **Три полносвязных слоя**: 4096 → 4096 → 1000 \n",
    "\n",
    "###  **Почему именно 3×3 свертки**\n",
    "\n",
    "- **Два слоя 3×3** дают рецептивное поле, эквивалентное одной свертке 5×5,  \n",
    "  но с **меньше параметров** и **двумя нелинейностями ReLU**.\n",
    "- Увеличивается глубина сети → выражательная способность.\n",
    "- Простота и универсальность.\n",
    "\n",
    "\n",
    "###  Формула для вычисления выходного размера\n",
    "\n",
    "$$\n",
    "O = \\left\\lfloor \\frac{W - K + 2P}{S} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "Где:\n",
    "\n",
    "- \\( W \\) — размер входа  \n",
    "- \\( K \\) — размер ядра (kernel size)  \n",
    "- \\( P \\) — паддинг (padding)  \n",
    "- \\( S \\) — страйд (stride)\n",
    "\n",
    "- Для свертки 3×3 с `padding=1, stride=1`:  \n",
    "размер не изменяется.  \n",
    "- MaxPool 2×2 (`stride=2`) уменьшает размер в 2 раза.\n",
    "\n",
    "\n",
    "### Размеры после каждого блока (для входа 224×224×3)\n",
    "\n",
    "| Блок | Операции | Выходной размер |\n",
    "|------|-----------|----------------|\n",
    "| 1 | 2×Conv3×3(64) + Pool | 112×112×64 |\n",
    "| 2 | 2×Conv3×3(128) + Pool | 56×56×128 |\n",
    "| 3 | 3×Conv3×3(256) + Pool | 28×28×256 |\n",
    "| 4 | 3×Conv3×3(512) + Pool | 14×14×512 |\n",
    "| 5 | 3×Conv3×3(512) + Pool | 7×7×512 |\n",
    "| FC | Flatten → 4096 → 4096 → 1000 | — |\n",
    "\n",
    "\n",
    "###  Количество параметров\n",
    "\n",
    "| Модель | Кол-во параметров | Размер (прибл.) |\n",
    "|---------|-------------------|-----------------|\n",
    "| **VGG16** | ≈ 138 млн | ~528 МБ |\n",
    "| **VGG19** | ≈ 144 млн | ~550 МБ |\n",
    "\n",
    "Большая часть параметров приходится на FC-слои (первый FC: 25088×4096 ≈ 102 млн).\n",
    "\n",
    "\n",
    "\n",
    "###  Формула подсчета параметров в Conv-слое\n",
    "\n",
    "$$\n",
    "\\text{params} = F \\times (C_{in} \\times K \\times K) + F\n",
    "$$\n",
    "где  \n",
    "$F$ — число фильтров,  \n",
    "$C_{in}$ — число входных каналов,  \n",
    "$K$ — размер ядра,  \n",
    "$F$ (в конце) — смещения (bias).\n",
    "\n",
    "**Пример:** Conv(3×3, 3→64)  \n",
    "→ $( 64 \\times (3 \\times 3 \\times 3) + 64 = 1,792 )$ параметра.\n",
    "\n",
    "\n",
    "###  Отличия VGG16 vs VGG19\n",
    "\n",
    "| Характеристика | VGG16 | VGG19 |\n",
    "|----------------|--------|--------|\n",
    "| Conv-слоёв | 13 | 16 |\n",
    "| FC-слоёв | 3 | 3 |\n",
    "| Параметров | ~138 млн | ~144 млн |\n",
    "| Скорость | Быстрее | Медленнее |\n",
    "| Точность | Чуть ниже | Немного выше |\n",
    "\n",
    "\n",
    "###  Плюсы и минусы\n",
    "\n",
    "**Плюсы:**\n",
    "- Простая, логичная архитектура.\n",
    "- Хорошо переносится на новые задачи (transfer learning).\n",
    "- Отличная модель для обучения принципов CNN.\n",
    "\n",
    "**Минусы:**\n",
    "- Очень много параметров → тяжёлая и медленная.\n",
    "- Неэффективна для мобильных и edge-устройств.\n",
    "- FC-часть занимает 90% веса модели.\n",
    "\n",
    "\n",
    "###  Использование в transfer learning\n",
    "\n",
    "- Удаляем/замораживаем FC-слои.\n",
    "- Используем выход feature maps (7×7×512) как эмбеддинги.\n",
    "- Дообучаем только верхние слои на новой задаче.\n",
    "\n",
    "**PyTorch пример:**\n",
    "```python\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "vgg16.classifier[6] = nn.Linear(4096, 10)  # новые 10 классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c18cd",
   "metadata": {},
   "source": [
    "# **GoogleNet (Inception v1)**\n",
    "\n",
    "### **Что такое GoogleNet?**\n",
    "- GoogleNet (Inception v1) — архитектура сверточной нейронной сети, предложенная в 2014 году командой Google (Szegedy et al., 2014).  \n",
    "- Основная идея — использовать **Inception-блок**, который параллельно применяет свертки разных размеров (1×1, 3×3, 5×5) и MaxPooling, а затем конкатенирует результаты.  \n",
    "- Цель — увеличить **выразительность сети**, сохраняя **вычислительную эффективность** (меньше параметров по сравнению с VGG).\n",
    "\n",
    "### **Основные характеристики**\n",
    "- Глубина: 22 слоя с весами.  \n",
    "- Вход: 224×224×3 (как в ImageNet).  \n",
    "- Обучена на ImageNet (~1.2 млн изображений, 1000 классов).  \n",
    "- Использует **1×1 свертки** для уменьшения размерности и вычислительной нагрузки.  \n",
    "- В GoogleNet почти нет полностью связанных слоев (только небольшой FC слой в конце).\n",
    "\n",
    "### **Архитектура**\n",
    "\n",
    "Блок Inception с параллельными фильтрами и последующей конкатенацией\n",
    "\n",
    "Global Average Pooling → Fully Connected слой → Output\n",
    "1. Начало сети:  \n",
    "   Input → Conv 7×7, stride=2 → MaxPool 3×3, stride=2 → Conv 1×1 → Conv 3×3 → MaxPool 3×3  \n",
    "2. Основная часть — Inception-блоки:\n",
    "\n",
    "<img src=\"./CNN/googlenet.png\" width=\"1000\" height=\"400\" align=\"center\">\n",
    "\n",
    "- В Inception-блоке **каждая ветка получает вход с предыдущего слоя**, затем результаты объединяются.  \n",
    "- После нескольких Inception-блоков → Global Average Pooling → FC(1000) → Softmax.\n",
    "\n",
    "### **Почему именно 1×1, 3×3 и 5×5 свертки**\n",
    "- **1×1 Conv:** уменьшает количество каналов → уменьшение параметров.  \n",
    "- **3×3 и 5×5 Conv:** захватывают информацию на разных масштабах.  \n",
    "- **MaxPool:** добавляет устойчивость к локальным сдвигам.  \n",
    "\n",
    "### **Формула для подсчета параметров Conv-слоя**\n",
    "$$\n",
    "\\text{params} = F \\times (C_{in} \\times K \\times K) + F\n",
    "$$\n",
    "- $F$ — число фильтров, $C_{in}$ — число входных каналов, $K$ — размер ядра.  \n",
    "- **Пример:** Conv 1×1, 192 входных каналов, 64 фильтра → $64 \\times (192 \\times 1 \\times 1) + 64 = 12352$ параметров.\n",
    "\n",
    "### **Размер выходов после Inception-блоков**\n",
    "- Если вход $W \\times H \\times C$, а stride=1, padding подобран так, чтобы размер не менялся → выход тоже $W \\times H \\times C'$  \n",
    "- После Global Average Pooling: $1 \\times 1 \\times 1024$\n",
    "\n",
    "### **Количество параметров**\n",
    "| Модель       | Кол-во параметров | Размер |\n",
    "|-------------|-----------------|--------|\n",
    "| GoogleNet   | ≈ 6.8 млн       | ~27 МБ |\n",
    "\n",
    "- Значительно меньше, чем у VGG (~138 млн).  \n",
    "- Много параметров экономится за счет **1×1 сверток** и отсутствия больших FC слоев.\n",
    "\n",
    "### **Плюсы и минусы**\n",
    "**Плюсы:**  \n",
    "- Компактная и эффективная по памяти.  \n",
    "- Высокая точность на ImageNet.  \n",
    "- Многоуровневое представление с разных масштабов.  \n",
    "\n",
    "**Минусы:**  \n",
    "- Сложнее архитектура → труднее для понимания.  \n",
    "- Для мобильных устройств лучше использовать Inception v3 или v4 с оптимизациями.\n",
    "\n",
    "### **Использование в transfer learning**\n",
    "- Можно удалить FC слой и использовать **выход Global Average Pooling** как feature vector.  \n",
    "- Дообучение только верхних слоев или добавление нового классификатора.\n",
    "\n",
    "**PyTorch пример:**\n",
    "```python\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "googlenet = models.googlenet(pretrained=True)\n",
    "for param in googlenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# заменяем FC слой на 10 классов\n",
    "googlenet.fc = nn.Linear(1024, 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6aca42",
   "metadata": {},
   "source": [
    "# **ResNet**\n",
    "\n",
    "### **Что такое ResNet ?**\n",
    "\n",
    "- ResNet (*Residual Network*, Microsoft Research) — семейство глубоких сверточных сетей, предложенное в 2015 (He et al.).  \n",
    "- **Главная идея — residual connections (остаточные соединения)**, позволяющие строить очень глубокие сети без проблемы исчезающего градиента.\n",
    "\n",
    "**Основные варианты:**\n",
    "- **ResNet18** — 18 слоёв (8 conv-блоков + FC).  \n",
    "- **ResNet34** — 34 слоя.  \n",
    "- **ResNet50** — 50 слоёв (с использованием bottleneck-блоков).  \n",
    "- **ResNet101, ResNet152** — ещё глубже, для более сложных задач.\n",
    "\n",
    "- Обучена на ImageNet (224×224×3, 1000 классов, ≈1.2M изображений).  \n",
    "- Цель: точное извлечение признаков из изображений при минимальной потере градиента в глубоких сетях.\n",
    "\n",
    "\n",
    "### **Архитектура ResNet50**\n",
    "<img src=\"./CNN/resnet50.png\" width=\"1000\" height=\"400\" align=\"center\">\n",
    "\n",
    "**Входной этап:** \n",
    " - **Zero Padding**: нулевое заполнение входного изображения для сохранения размерности.\n",
    " - **Conv2D**: начальная свертка (обычно 7x7, stride=2) для извлечения признаков. \n",
    " - **BatchNorm**: нормализация активаций по пакету — стабилизирует обучение. \n",
    " - **ReLU**: нелинейность для введения сложных зависимостей. \n",
    " - **MaxPool**: уменьшение пространственного размера (обычно 3x3, stride=2). \n",
    "\n",
    "**Основные блоки (Residual Blocks):** \n",
    " - Повторяется 4 раза (каждый \"блок\" = группа слоев с одинаковым размером карты признаков). \n",
    " - Каждый блок начинается с Conv Block — изменяет количество каналов и/или размер карты (downsampling).\n",
    " - За ним следует N × ID Block (Identity Block) — сохраняет размер карты, содержит skip connection (суммирование входа и выхода).\n",
    " - Skip connections позволяют градиентам проходить напрямую, решая проблему затухания градиента. \n",
    "\n",
    "**Выходной этап:** \n",
    " - Avg Pool: глобальное среднее пулинг по всем пространственным размерностям → вектор фиксированной длины.\n",
    " - Flattening: преобразование в одномерный вектор (если не сделано в Avg Pool).\n",
    " - FC (Fully Connected): полносвязный слой с softmax (для классификации) или другим выходным слоем.\n",
    "\n",
    "### **Пример параметров ResNet50 по этапам**\n",
    "\n",
    "| Этап | Блоки | Выходной размер карты признаков |\n",
    "|------|-------|-------------------------------|\n",
    "| Conv1 + MaxPool | — | 56×56×64 |\n",
    "| Stage2 | 1 Conv Block + 2 Identity Block | 56×56×256 |\n",
    "| Stage3 | 1 Conv Block + 3 Identity Block | 28×28×512 |\n",
    "| Stage4 | 1 Conv Block + 5 Identity Block | 14×14×1024 |\n",
    "| Stage5 | 1 Conv Block + 2 Identity Block | 7×7×2048 |\n",
    "| AvgPool | — | 1×1×2048 |\n",
    "| FC | — | 1000 классов |\n",
    "\n",
    "\n",
    "### **Residual Block (Остаточный блок)**\n",
    "\n",
    "- Основная формула:\n",
    "$$\n",
    "\\mathbf{y} = F(\\mathbf{x}) + \\mathbf{x}\n",
    "$$\n",
    "- $(F(\\mathbf{x})$) — нелинейное преобразование (Conv → BN → ReLU).  \n",
    "- $(\\mathbf{x}$) — вход блока.  \n",
    "\n",
    "**Особенности:**\n",
    "- Легкое прохождение градиента через skip connection.  \n",
    "- Сеть может «игнорировать» некоторые блоки (обнулять F(x)) при необходимости.  \n",
    "- Использование bottleneck уменьшает число параметров, сохраняя большую глубину.\n",
    "\n",
    "\n",
    "### **Почему residual connections важны**\n",
    "\n",
    "- Без них глубокие сети (>50 слоев) плохо обучаются из-за исчезающих градиентов.  \n",
    "- Позволяют строить сверхглубокие сети (ResNet101, ResNet152) без потери точности.  \n",
    "- Skip connections → ускорение сходимости и более стабильное обучение.\n",
    "\n",
    "\n",
    "### **Формула подсчета выходного размера**\n",
    "\n",
    "$$\n",
    "O = \\left\\lfloor \\frac{W - K + 2P}{S} \\right\\rfloor + 1\n",
    "$$\n",
    "\n",
    "- Padding = stride/2 обычно сохраняет размерность.  \n",
    "- Downsampling происходит с помощью stride=2 в Conv Block.\n",
    "\n",
    "\n",
    "### **Количество параметров ResNet**\n",
    "\n",
    "| Модель | Параметры | Размер (прибл.) |\n",
    "|--------|-----------|----------------|\n",
    "| ResNet18 | 11.7 млн | 44 МБ |\n",
    "| ResNet34 | 21.8 млн | 83 МБ |\n",
    "| ResNet50 | 25.6 млн | 98 МБ |\n",
    "| ResNet101 | 44.5 млн | 170 МБ |\n",
    "| ResNet152 | 60.2 млн | 230 МБ |\n",
    "\n",
    "<br><br/>\n",
    "> Замечание: ResNet гораздо легче VGG при схожей или лучшей точности благодаря skip connections и меньшему числу FC-слоев.\n",
    "\n",
    "\n",
    "\n",
    "### **Плюсы и минусы**\n",
    "\n",
    "**Плюсы:**\n",
    "- Возможность строить сверхглубокие сети (50–152 слоя и выше).  \n",
    "- Отличная точность на ImageNet.  \n",
    "- Skip connections ускоряют обучение и улучшают распространение градиента.  \n",
    "- Bottleneck блоки уменьшают количество параметров.\n",
    "\n",
    "**Минусы:**\n",
    "- Архитектура сложнее, чем у VGG.  \n",
    "- Иногда дороже вычислительно (особенно при bottleneck блоках).  \n",
    "- Меньше «интуитивной наглядности» слоев.\n",
    "\n",
    "\n",
    "### **Использование в Transfer Learning**\n",
    "\n",
    "- Заморозка feature extractor (сверточных слоев).  \n",
    "- Замена FC слоя на новый для нужного числа классов.  \n",
    "- ResNet feature maps обычно: 7×7×2048 (ResNet50).\n",
    "\n",
    "**PyTorch пример:**\n",
    "```python\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "\n",
    "# Загружаем pretrained ResNet50\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "# Замораживаем все свертки\n",
    "for param in resnet50.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Заменяем классификатор\n",
    "num_ftrs = resnet50.fc.in_features\n",
    "resnet50.fc = nn.Linear(num_ftrs, 10)  # новые 10 классов\n",
    "\n",
    "# Пример forward pass\n",
    "x = torch.randn(2, 3, 224, 224)  # batch из 2 изображений\n",
    "outputs = resnet50(x)\n",
    "print(outputs.shape)  # torch.Size([2, 10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc38b8bb",
   "metadata": {},
   "source": [
    "# **EfficientNetB7**\n",
    "\n",
    "### **Что такое EfficientNet?**\n",
    "\n",
    "- EfficientNet (Google Research, 2019) — семейство сверточных сетей, созданное для **оптимального баланса точности и вычислительной эффективности**.  \n",
    "- **Ключевая идея — compound scaling (компаунд-масштабирование)**: одновременно увеличиваем глубину, ширину и разрешение сети по заранее найденным коэффициентам, а не только один параметр, как в ResNet.\n",
    "\n",
    "**Основные преимущества:**\n",
    "- Эффективное использование ресурсов.  \n",
    "- Высокая точность при относительно малом числе параметров.  \n",
    "- Легко масштабируется: B0 → B7, где B7 — самая крупная и точная модель.\n",
    "\n",
    "\n",
    "### **Основные варианты EfficientNet**\n",
    "\n",
    "| Модель | Параметры | Input size | Top-1 Accuracy |\n",
    "|--------|-----------|------------|----------------|\n",
    "| B0     | 5.3 млн   | 224×224    | 77.1%          |\n",
    "| B1     | 7.8 млн   | 240×240    | 79.2%          |\n",
    "| B2     | 9.2 млн   | 260×260    | 80.2%          |\n",
    "| …      | …         | …          | …              |\n",
    "| B7     | 66.3 млн  | 600×600    | 84.3%          |\n",
    "\n",
    "<br><br/>\n",
    "> Замечание: B7 имеет меньше параметров, чем ResNet152 (~60.2 млн), но превосходит её по точности благодаря более эффективной архитектуре.\n",
    "\n",
    "\n",
    "### **Архитектура EfficientNetB7**\n",
    "\n",
    "<img src=\"./CNN/B7.png\" width=\"1000\" height=\"400\" align=\"center\">\n",
    "\n",
    "**Входной этап:**\n",
    " - Input Image (600×600×3) → Preprocessing (нормализация, аугментация)\n",
    "\n",
    "**Основной блок (MBConv):**\n",
    " - Использует MobileNetV2-подобные MBConv блоки (Mobile Inverted Bottleneck Convolution)\n",
    " - Содержат depthwise conv + pointwise conv + SE (Squeeze-and-Excitation) attention\n",
    " - Включают skip connection (аналог ResNet, но с SE-блоком)\n",
    "\n",
    "**Структура:**\n",
    " - Stage 1: Initial Conv (3x3, stride=2) → BN → Swish\n",
    " - Stages 2–9: Повторяющиеся MBConv блоки с разными размерами ядер и количеством каналов\n",
    " - Global Average Pooling → Dropout → Dense Layer → Softmax\n",
    "\n",
    "\n",
    " ### **MBConv Block**\n",
    "\n",
    "1. **Pointwise Conv (1x1)** → расширение числа каналов  \n",
    "2. **Depthwise Conv (3x3 или 5x5)** → пространственная фильтрация  \n",
    "3. **Squeeze-and-Excitation (SE)** → attention механизм, взвешивание каналов  \n",
    "4. **Pointwise Conv (1x1)** → сжатие до исходного числа каналов  \n",
    "5. **Skip Connection** (если input == output) → суммирование  \n",
    "\n",
    "**Преимущества:** низкие вычислительные затраты, высокая точность, встроенный attention.\n",
    "\n",
    "\n",
    "### **Compound Scaling**\n",
    "\n",
    "Формула масштабирования:\n",
    "$$\n",
    "\\text{depth} = \\alpha^\\phi, \\quad \\text{width} = \\beta^\\phi, \\quad \\text{resolution} = \\gamma^\\phi\n",
    "$$\n",
    "- α, β, γ — коэффициенты, найденные через grid search (α≈1.2, β≈1.1, γ≈1.15)  \n",
    "- φ — коэффициент масштабирования (для B7: φ=7)  \n",
    "\n",
    "Пример для B7:  \n",
    "- Глубина: B0 × 1.2⁷ ≈ 8.5× больше  \n",
    "- Ширина: B0 × 1.1⁷ ≈ 2× больше  \n",
    "- Разрешение: B0 × 1.15⁷ ≈ 2.7× больше (вход 600×600 вместо 224×224)\n",
    "\n",
    "\n",
    "### **Размеры входа и выхода**\n",
    "\n",
    "- **Input:** 600×600×3  \n",
    "- **Output feature map:** 10×10×2560 (после последнего сверточного слоя)  \n",
    "- **Global AvgPool:** 2560-dim vector  \n",
    "- **FC layer:** 1000 классов (ImageNet)\n",
    "\n",
    "\n",
    "### **Плюсы и минусы**\n",
    "\n",
    "**Плюсы:**  \n",
    "- Высокая точность при меньшем числе параметров, чем ResNet152  \n",
    "- Эффективное использование ресурсов благодаря compound scaling  \n",
    "- MBConv + SE attention улучшают качество признаков  \n",
    "- Отлично подходит для transfer learning и edge-устройств  \n",
    "- Легко масштабируется B0–B7  \n",
    "\n",
    "**Минусы:**  \n",
    "- Большой входной размер → высокие требования к памяти  \n",
    "- Вычислительно дорого для инференса (особенно B7)  \n",
    "- Более сложная архитектура, чем VGG/ResNet — труднее интерпретировать  \n",
    "- Может требовать fine-tuning на малых датасетах\n",
    "\n",
    "\n",
    "### **Transfer Learning с EfficientNetB7 (PyTorch)**\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import timm  # pip install timm\n",
    "\n",
    "# Загрузка EfficientNetB7 pretrained\n",
    "model = timm.create_model('efficientnet_b7', pretrained=True)\n",
    "\n",
    "# Заморозка всех слоев\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Замена последнего полносвязного слоя на новый (для N классов)\n",
    "num_ftrs = model.classifier.in_features  # обычно 2560 для B7\n",
    "model.classifier = nn.Linear(num_ftrs, 10)  # пример: 10 классов\n",
    "\n",
    "# Пример forward pass\n",
    "x = torch.randn(2, 3, 600, 600)  # batch из 2 изображений\n",
    "outputs = model(x)\n",
    "print(outputs.shape)  # torch.Size([2, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafbf8c7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
